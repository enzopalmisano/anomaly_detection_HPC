{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/reboot/anaconda3/envs/Anomaly_Detection_HPC/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/reboot/anaconda3/envs/Anomaly_Detection_HPC/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "classifier = load_model('./models/classifier_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Node r183c09s03 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3758, 126)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./my_code/norm_dataset/r183c09s03_normalised.csv\")\n",
    "list_col1 = list(df.columns.values)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"timestamp\",axis=1)\n",
    "df_noAn = df[df.label==0]\n",
    "df_An = df[df.label==1]\n",
    "labels_noAn = df_noAn[\"label\"]\n",
    "labels_An = df_An[\"label\"]\n",
    "#Drop label col for prediction\n",
    "df_noAn = df_noAn.drop(\"label\",axis=1)\n",
    "df_An = df_An.drop(\"label\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_prob_noAn = classifier.predict(df_noAn)\n",
    "predict_prob_An = classifier.predict(df_An)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_class(predicted_probabilities, threshold=0.5):\n",
    "    classes = []\n",
    "    for i in range(len(predicted_probabilities)):\n",
    "        if(predicted_probabilities[i] >= threshold):\n",
    "            classes.append(1)\n",
    "        else:\n",
    "            classes.append(0)\n",
    "    return np.asarray(classes)\n",
    "\n",
    "classes_An = assign_class(predict_prob_An)\n",
    "classes_NoAn = assign_class(predict_prob_noAn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :0.0\n",
      "f1Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "#metrics for df anomaly\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy :\"+str(accuracy_score(labels_An,classes_An)*100))\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"f1Score: \"+str(f1_score(labels_An,classes_An)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0],\n",
       "       [75,  0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(labels_An, classes_An)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :99.94569644311703\n",
      "f1Score: 0.9997284084736556\n"
     ]
    }
   ],
   "source": [
    "#metrics for df no anomaly\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy :\"+str(accuracy_score(labels_noAn,classes_NoAn)*100))\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"f1Score: \"+str(f1_score(labels_noAn,classes_NoAn,average='weighted')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3681,    2],\n",
       "       [   0,    0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(labels_noAn, classes_NoAn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :97.95103778605642\n",
      "f1Score: 0.9698982986047743\n"
     ]
    }
   ],
   "source": [
    "#metrics for total dataset\n",
    "labels = df[\"label\"]\n",
    "df_total = df.drop(\"label\",axis=1)\n",
    "predict_prob = classifier.predict(df_total)\n",
    "classes = assign_class(predict_prob)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy :\"+str(accuracy_score(labels,classes)*100))\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"f1Score: \"+str(f1_score(labels,classes,average='weighted')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3681,    2],\n",
       "       [  75,    0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(labels, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Node r183c09s04 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3759, 126)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./my_code/norm_dataset/r183c09s04_normalised.csv\")\n",
    "list_col1 = list(df.columns.values)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"timestamp\",axis=1)\n",
    "df_noAn = df[df.label==0]\n",
    "df_An = df[df.label==1]\n",
    "labels_noAn = df_noAn[\"label\"]\n",
    "labels_An = df_An[\"label\"]\n",
    "#Drop label col for prediction\n",
    "df_noAn = df_noAn.drop(\"label\",axis=1)\n",
    "df_An = df_An.drop(\"label\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_prob_noAn = classifier.predict(df_noAn)\n",
    "predict_prob_An = classifier.predict(df_An)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_An = assign_class(predict_prob_An)\n",
    "classes_NoAn = assign_class(predict_prob_noAn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :9.333333333333334\n",
      "f1Score: 0.17073170731707318\n"
     ]
    }
   ],
   "source": [
    "#metrics for df anomaly\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy :\"+str(accuracy_score(labels_An,classes_An)*100))\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"f1Score: \"+str(f1_score(labels_An,classes_An)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :99.5928338762215\n",
      "f1Score: 0.9979600163198695\n"
     ]
    }
   ],
   "source": [
    "#metrics for df no anomaly\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy :\"+str(accuracy_score(labels_noAn,classes_NoAn)*100))\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"f1Score: \"+str(f1_score(labels_noAn,classes_NoAn,average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :97.79196594839053\n",
      "f1Score: 0.9719662492404658\n"
     ]
    }
   ],
   "source": [
    "#metrics for total dataset\n",
    "labels = df[\"label\"]\n",
    "df_total = df.drop(\"label\",axis=1)\n",
    "predict_prob = classifier.predict(df_total)\n",
    "classes = assign_class(predict_prob)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy :\"+str(accuracy_score(labels,classes)*100))\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"f1Score: \"+str(f1_score(labels,classes,average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3669,   15],\n",
       "       [  68,    7]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(labels, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Node r183c10s01 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3760, 126)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./my_code/norm_dataset/r183c10s01_normalised.csv\")\n",
    "list_col1 = list(df.columns.values)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"timestamp\",axis=1)\n",
    "df_noAn = df[df.label==0]\n",
    "df_An = df[df.label==1]\n",
    "labels_noAn = df_noAn[\"label\"]\n",
    "labels_An = df_An[\"label\"]\n",
    "#Drop label col for prediction\n",
    "df_noAn = df_noAn.drop(\"label\",axis=1)\n",
    "df_An = df_An.drop(\"label\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_prob_noAn = classifier.predict(df_noAn)\n",
    "predict_prob_An = classifier.predict(df_An)\n",
    "classes_An = assign_class(predict_prob_An)\n",
    "classes_NoAn = assign_class(predict_prob_noAn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :25.333333333333336\n",
      "f1Score: 0.4042553191489362\n"
     ]
    }
   ],
   "source": [
    "#metrics for df anomaly\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy :\"+str(accuracy_score(labels_An,classes_An)*100))\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"f1Score: \"+str(f1_score(labels_An,classes_An)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :62.469470827679785\n",
      "f1Score: 0.7689994989143143\n"
     ]
    }
   ],
   "source": [
    "#metrics for df no anomaly\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy :\"+str(accuracy_score(labels_noAn,classes_NoAn)*100))\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"f1Score: \"+str(f1_score(labels_noAn,classes_NoAn,average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :61.72872340425531\n",
      "f1Score: 0.7471894901365168\n"
     ]
    }
   ],
   "source": [
    "#metrics for total dataset\n",
    "labels = df[\"label\"]\n",
    "df_total = df.drop(\"label\",axis=1)\n",
    "predict_prob = classifier.predict(df_total)\n",
    "classes = assign_class(predict_prob)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy :\"+str(accuracy_score(labels,classes)*100))\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"f1Score: \"+str(f1_score(labels,classes,average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2302, 1383],\n",
       "       [  56,   19]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(labels, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Node r183c10s02 </h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3756, 126)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./my_code/norm_dataset/r183c10s02_normalised.csv\")\n",
    "list_col1 = list(df.columns.values)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"timestamp\",axis=1)\n",
    "df_noAn = df[df.label==0]\n",
    "df_An = df[df.label==1]\n",
    "labels_noAn = df_noAn[\"label\"]\n",
    "labels_An = df_An[\"label\"]\n",
    "#Drop label col for prediction\n",
    "df_noAn = df_noAn.drop(\"label\",axis=1)\n",
    "df_An = df_An.drop(\"label\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_prob_noAn = classifier.predict(df_noAn)\n",
    "predict_prob_An = classifier.predict(df_An)\n",
    "classes_An = assign_class(predict_prob_An)\n",
    "classes_NoAn = assign_class(predict_prob_noAn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :34.66666666666667\n",
      "f1Score: 0.5148514851485149\n"
     ]
    }
   ],
   "source": [
    "#metrics for df anomaly\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy :\"+str(accuracy_score(labels_An,classes_An)*100))\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"f1Score: \"+str(f1_score(labels_An,classes_An)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :99.48383591415376\n",
      "f1Score: 0.9974125017023016\n"
     ]
    }
   ],
   "source": [
    "#metrics for df no anomaly\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy :\"+str(accuracy_score(labels_noAn,classes_NoAn)*100))\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"f1Score: \"+str(f1_score(labels_noAn,classes_NoAn,average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :98.18956336528221\n",
      "f1Score: 0.9796693256158113\n"
     ]
    }
   ],
   "source": [
    "#metrics for total dataset\n",
    "labels = df[\"label\"]\n",
    "df_total = df.drop(\"label\",axis=1)\n",
    "predict_prob = classifier.predict(df_total)\n",
    "classes = assign_class(predict_prob)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy :\"+str(accuracy_score(labels,classes)*100))\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"f1Score: \"+str(f1_score(labels,classes,average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3662,   19],\n",
       "       [  49,   26]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(labels, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Node r183c10s03 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3758, 126)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./my_code/norm_dataset/r183c10s03_normalised.csv\")\n",
    "list_col1 = list(df.columns.values)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"timestamp\",axis=1)\n",
    "df_noAn = df[df.label==0]\n",
    "df_An = df[df.label==1]\n",
    "labels_noAn = df_noAn[\"label\"]\n",
    "labels_An = df_An[\"label\"]\n",
    "#Drop label col for prediction\n",
    "df_noAn = df_noAn.drop(\"label\",axis=1)\n",
    "df_An = df_An.drop(\"label\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_prob_noAn = classifier.predict(df_noAn)\n",
    "predict_prob_An = classifier.predict(df_An)\n",
    "classes_An = assign_class(predict_prob_An)\n",
    "classes_NoAn = assign_class(predict_prob_noAn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :0.0\n",
      "f1Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "#metrics for df anomaly\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy :\"+str(accuracy_score(labels_An,classes_An)*100))\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"f1Score: \"+str(f1_score(labels_An,classes_An)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :99.89139288623404\n",
      "f1Score: 0.9994566693833198\n"
     ]
    }
   ],
   "source": [
    "#metrics for df no anomaly\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy :\"+str(accuracy_score(labels_noAn,classes_NoAn)*100))\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"f1Score: \"+str(f1_score(labels_noAn,classes_NoAn,average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :97.89781798829165\n",
      "f1Score: 0.9696320119695526\n"
     ]
    }
   ],
   "source": [
    "#metrics for total dataset\n",
    "labels = df[\"label\"]\n",
    "df_total = df.drop(\"label\",axis=1)\n",
    "predict_prob = classifier.predict(df_total)\n",
    "classes = assign_class(predict_prob)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy :\"+str(accuracy_score(labels,classes)*100))\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"f1Score: \"+str(f1_score(labels,classes,average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3679,    4],\n",
       "       [  75,    0]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(labels, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> r183c11s01 </h2> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3151, 126)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./my_code/norm_dataset/r183c11s01_normalised.csv\")\n",
    "list_col1 = list(df.columns.values)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"timestamp\",axis=1)\n",
    "df_noAn = df[df.label==0]\n",
    "df_An = df[df.label==1]\n",
    "labels_noAn = df_noAn[\"label\"]\n",
    "labels_An = df_An[\"label\"]\n",
    "#Drop label col for prediction\n",
    "df_noAn = df_noAn.drop(\"label\",axis=1)\n",
    "df_An = df_An.drop(\"label\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_prob_noAn = classifier.predict(df_noAn)\n",
    "predict_prob_An = classifier.predict(df_An)\n",
    "classes_An = assign_class(predict_prob_An)\n",
    "classes_NoAn = assign_class(predict_prob_noAn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :0.0\n",
      "f1Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "#metrics for df anomaly\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy :\"+str(accuracy_score(labels_An,classes_An)*100))\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"f1Score: \"+str(f1_score(labels_An,classes_An)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :99.9675535366645\n",
      "f1Score: 0.9998377413597274\n"
     ]
    }
   ],
   "source": [
    "#metrics for df no anomaly\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy :\"+str(accuracy_score(labels_noAn,classes_NoAn)*100))\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"f1Score: \"+str(f1_score(labels_noAn,classes_NoAn,average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :97.7784830212631\n",
      "f1Score: 0.9671158044657666\n"
     ]
    }
   ],
   "source": [
    "#metrics for total dataset\n",
    "labels = df[\"label\"]\n",
    "df_total = df.drop(\"label\",axis=1)\n",
    "predict_prob = classifier.predict(df_total)\n",
    "classes = assign_class(predict_prob)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy :\"+str(accuracy_score(labels,classes)*100))\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"f1Score: \"+str(f1_score(labels,classes,average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3081,    1],\n",
       "       [  69,    0]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(labels, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>r183c11s02</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3679, 126)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./my_code/norm_dataset/r183c11s02_normalised.csv\")\n",
    "list_col1 = list(df.columns.values)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"timestamp\",axis=1)\n",
    "df_noAn = df[df.label==0]\n",
    "df_An = df[df.label==1]\n",
    "labels_noAn = df_noAn[\"label\"]\n",
    "labels_An = df_An[\"label\"]\n",
    "#Drop label col for prediction\n",
    "df_noAn = df_noAn.drop(\"label\",axis=1)\n",
    "df_An = df_An.drop(\"label\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_prob_noAn = classifier.predict(df_noAn)\n",
    "predict_prob_An = classifier.predict(df_An)\n",
    "classes_An = assign_class(predict_prob_An)\n",
    "classes_NoAn = assign_class(predict_prob_noAn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :0.0\n",
      "f1Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "#metrics for df anomaly\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy :\"+str(accuracy_score(labels_An,classes_An)*100))\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"f1Score: \"+str(f1_score(labels_An,classes_An)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :99.94459833795014\n",
      "f1Score: 0.999722914934885\n"
     ]
    }
   ],
   "source": [
    "#metrics for df no anomaly\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy :\"+str(accuracy_score(labels_noAn,classes_NoAn)*100))\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"f1Score: \"+str(f1_score(labels_noAn,classes_NoAn,average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :98.07012775210654\n",
      "f1Score: 0.9716842628931099\n"
     ]
    }
   ],
   "source": [
    "#metrics for total dataset\n",
    "labels = df[\"label\"]\n",
    "df_total = df.drop(\"label\",axis=1)\n",
    "predict_prob = classifier.predict(df_total)\n",
    "classes = assign_class(predict_prob)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy :\"+str(accuracy_score(labels,classes)*100))\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"f1Score: \"+str(f1_score(labels,classes,average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3608,    2],\n",
       "       [  69,    0]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(labels, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>r183c11s03</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3678, 126)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./my_code/norm_dataset/r183c11s03_normalised.csv\")\n",
    "list_col1 = list(df.columns.values)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"timestamp\",axis=1)\n",
    "df_noAn = df[df.label==0]\n",
    "df_An = df[df.label==1]\n",
    "labels_noAn = df_noAn[\"label\"]\n",
    "labels_An = df_An[\"label\"]\n",
    "#Drop label col for prediction\n",
    "df_noAn = df_noAn.drop(\"label\",axis=1)\n",
    "df_An = df_An.drop(\"label\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_prob_noAn = classifier.predict(df_noAn)\n",
    "predict_prob_An = classifier.predict(df_An)\n",
    "classes_An = assign_class(predict_prob_An)\n",
    "classes_NoAn = assign_class(predict_prob_noAn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :1.4492753623188406\n",
      "f1Score: 0.02857142857142857\n"
     ]
    }
   ],
   "source": [
    "#metrics for df anomaly\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy :\"+str(accuracy_score(labels_An,classes_An)*100))\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"f1Score: \"+str(f1_score(labels_An,classes_An)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :99.94458298697701\n",
      "f1Score: 0.9997228381374723\n"
     ]
    }
   ],
   "source": [
    "#metrics for df no anomaly\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy :\"+str(accuracy_score(labels_noAn,classes_NoAn)*100))\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"f1Score: \"+str(f1_score(labels_noAn,classes_NoAn,average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :98.09679173463839\n",
      "f1Score: 0.9723311038906551\n"
     ]
    }
   ],
   "source": [
    "#metrics for total dataset\n",
    "labels = df[\"label\"]\n",
    "df_total = df.drop(\"label\",axis=1)\n",
    "predict_prob = classifier.predict(df_total)\n",
    "classes = assign_class(predict_prob)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy :\"+str(accuracy_score(labels,classes)*100))\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"f1Score: \"+str(f1_score(labels,classes,average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3607,    2],\n",
       "       [  68,    1]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(labels, classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
