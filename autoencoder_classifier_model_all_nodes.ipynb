{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Dense,Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and testing ML models: Autoencoder and Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"my_code/norm_dataset/dataset_complete_2\")\n",
    "input_data = dataset.drop(labels=['label'], axis=1)\n",
    "labels = dataset.loc[:,'label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "del input_data[\"Unnamed: 0\"]\n",
    "input_dim = input_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg:boottime</th>\n",
       "      <th>var:boottime</th>\n",
       "      <th>avg:bytes_in</th>\n",
       "      <th>var:bytes_in</th>\n",
       "      <th>avg:bytes_out</th>\n",
       "      <th>var:bytes_out</th>\n",
       "      <th>avg:core_freq_avg</th>\n",
       "      <th>var:core_freq_avg</th>\n",
       "      <th>avg:core_freq_max</th>\n",
       "      <th>var:core_freq_max</th>\n",
       "      <th>...</th>\n",
       "      <th>avg:SysBrd_3_3V</th>\n",
       "      <th>var:SysBrd_3_3V</th>\n",
       "      <th>avg:SysBrd_5V</th>\n",
       "      <th>var:SysBrd_5V</th>\n",
       "      <th>avg:Sys_Power</th>\n",
       "      <th>var:Sys_Power</th>\n",
       "      <th>avg:Sys_Utilization</th>\n",
       "      <th>var:Sys_Utilization</th>\n",
       "      <th>avg:System_Air_Flow</th>\n",
       "      <th>var:System_Air_Flow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.062039e-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>2.283939e-07</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>1.388315e-07</td>\n",
       "      <td>0.278500</td>\n",
       "      <td>0.011063</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000e-01</td>\n",
       "      <td>3.420313e-27</td>\n",
       "      <td>0.25</td>\n",
       "      <td>6.213460e-27</td>\n",
       "      <td>0.338384</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.369942</td>\n",
       "      <td>0.0225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.062039e-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>4.517481e-10</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>2.637226e-11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>6.213460e-27</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.520231</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.062039e-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>6.850317e-13</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>1.025377e-10</td>\n",
       "      <td>0.932278</td>\n",
       "      <td>0.019878</td>\n",
       "      <td>0.949528</td>\n",
       "      <td>0.014804</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>6.213460e-27</td>\n",
       "      <td>0.883838</td>\n",
       "      <td>0.007134</td>\n",
       "      <td>0.810101</td>\n",
       "      <td>0.013332</td>\n",
       "      <td>0.635838</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.062039e-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>3.753747e-08</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>2.935972e-08</td>\n",
       "      <td>0.562667</td>\n",
       "      <td>0.085836</td>\n",
       "      <td>0.942333</td>\n",
       "      <td>0.008965</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>6.213460e-27</td>\n",
       "      <td>0.262626</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>0.404624</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.062039e-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>6.728702e-07</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>3.013188e-07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>6.213460e-27</td>\n",
       "      <td>0.767677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.808081</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.549133</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66353</th>\n",
       "      <td>3.267814e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>7.872900e-10</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>1.104144e-09</td>\n",
       "      <td>0.370972</td>\n",
       "      <td>0.052235</td>\n",
       "      <td>0.958556</td>\n",
       "      <td>0.009768</td>\n",
       "      <td>...</td>\n",
       "      <td>7.105427e-15</td>\n",
       "      <td>3.420313e-27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.540404</td>\n",
       "      <td>0.118906</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.306358</td>\n",
       "      <td>0.0025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66354</th>\n",
       "      <td>3.267814e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>2.449614e-07</td>\n",
       "      <td>0.009287</td>\n",
       "      <td>6.291883e-05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.105427e-15</td>\n",
       "      <td>3.420313e-27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.580808</td>\n",
       "      <td>0.003171</td>\n",
       "      <td>0.941414</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.473988</td>\n",
       "      <td>0.0150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66355</th>\n",
       "      <td>3.267814e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>3.200907e-08</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>1.103904e-09</td>\n",
       "      <td>0.252778</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.889833</td>\n",
       "      <td>0.002653</td>\n",
       "      <td>...</td>\n",
       "      <td>7.105427e-15</td>\n",
       "      <td>3.420313e-27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.494949</td>\n",
       "      <td>0.000793</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.002449</td>\n",
       "      <td>0.491329</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66356</th>\n",
       "      <td>3.267814e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006751</td>\n",
       "      <td>2.334798e-04</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>2.294753e-07</td>\n",
       "      <td>0.748000</td>\n",
       "      <td>0.068344</td>\n",
       "      <td>0.991861</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>...</td>\n",
       "      <td>7.105427e-15</td>\n",
       "      <td>3.420313e-27</td>\n",
       "      <td>0.75</td>\n",
       "      <td>6.213460e-27</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.635838</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66357</th>\n",
       "      <td>3.267814e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000896</td>\n",
       "      <td>5.715900e-07</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>2.978826e-07</td>\n",
       "      <td>0.841444</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.105427e-15</td>\n",
       "      <td>3.420313e-27</td>\n",
       "      <td>0.75</td>\n",
       "      <td>6.213460e-27</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.767677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.433526</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66358 rows Ã— 124 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       avg:boottime  var:boottime  avg:bytes_in  var:bytes_in  avg:bytes_out  \\\n",
       "0      1.062039e-05           0.0      0.000555  2.283939e-07       0.000335   \n",
       "1      1.062039e-05           0.0      0.000071  4.517481e-10       0.000033   \n",
       "2      1.062039e-05           0.0      0.000077  6.850317e-13       0.000039   \n",
       "3      1.062039e-05           0.0      0.000798  3.753747e-08       0.000196   \n",
       "4      1.062039e-05           0.0      0.000624  6.728702e-07       0.000368   \n",
       "...             ...           ...           ...           ...            ...   \n",
       "66353  3.267814e-07           0.0      0.000069  7.872900e-10       0.000161   \n",
       "66354  3.267814e-07           0.0      0.000816  2.449614e-07       0.009287   \n",
       "66355  3.267814e-07           0.0      0.000285  3.200907e-08       0.000067   \n",
       "66356  3.267814e-07           0.0      0.006751  2.334798e-04       0.000276   \n",
       "66357  3.267814e-07           0.0      0.000896  5.715900e-07       0.000613   \n",
       "\n",
       "       var:bytes_out  avg:core_freq_avg  var:core_freq_avg  avg:core_freq_max  \\\n",
       "0       1.388315e-07           0.278500           0.011063           1.000000   \n",
       "1       2.637226e-11           1.000000           0.000000           1.000000   \n",
       "2       1.025377e-10           0.932278           0.019878           0.949528   \n",
       "3       2.935972e-08           0.562667           0.085836           0.942333   \n",
       "4       3.013188e-07           1.000000           0.000000           1.000000   \n",
       "...              ...                ...                ...                ...   \n",
       "66353   1.104144e-09           0.370972           0.052235           0.958556   \n",
       "66354   6.291883e-05           1.000000           0.000000           1.000000   \n",
       "66355   1.103904e-09           0.252778           0.000594           0.889833   \n",
       "66356   2.294753e-07           0.748000           0.068344           0.991861   \n",
       "66357   2.978826e-07           0.841444           0.000104           1.000000   \n",
       "\n",
       "       var:core_freq_max  ...  avg:SysBrd_3_3V  var:SysBrd_3_3V  \\\n",
       "0               0.000000  ...     4.000000e-01     3.420313e-27   \n",
       "1               0.000000  ...     4.000000e-01     0.000000e+00   \n",
       "2               0.014804  ...     4.000000e-01     0.000000e+00   \n",
       "3               0.008965  ...     4.000000e-01     0.000000e+00   \n",
       "4               0.000000  ...     4.000000e-01     0.000000e+00   \n",
       "...                  ...  ...              ...              ...   \n",
       "66353           0.009768  ...     7.105427e-15     3.420313e-27   \n",
       "66354           0.000000  ...     7.105427e-15     3.420313e-27   \n",
       "66355           0.002653  ...     7.105427e-15     3.420313e-27   \n",
       "66356           0.001238  ...     7.105427e-15     3.420313e-27   \n",
       "66357           0.000000  ...     7.105427e-15     3.420313e-27   \n",
       "\n",
       "       avg:SysBrd_5V  var:SysBrd_5V  avg:Sys_Power  var:Sys_Power  \\\n",
       "0               0.25   6.213460e-27       0.338384       0.000000   \n",
       "1               0.25   6.213460e-27       0.616162       0.000000   \n",
       "2               0.25   6.213460e-27       0.883838       0.007134   \n",
       "3               0.25   6.213460e-27       0.262626       0.000000   \n",
       "4               0.25   6.213460e-27       0.767677       0.000000   \n",
       "...              ...            ...            ...            ...   \n",
       "66353           0.50   0.000000e+00       0.540404       0.118906   \n",
       "66354           0.50   0.000000e+00       0.580808       0.003171   \n",
       "66355           0.50   0.000000e+00       0.494949       0.000793   \n",
       "66356           0.75   6.213460e-27       0.363636       0.000000   \n",
       "66357           0.75   6.213460e-27       0.616162       0.000000   \n",
       "\n",
       "       avg:Sys_Utilization  var:Sys_Utilization  avg:System_Air_Flow  \\\n",
       "0                 0.020202             0.000000             0.369942   \n",
       "1                 0.989899             0.000000             0.520231   \n",
       "2                 0.810101             0.013332             0.635838   \n",
       "3                 0.036364             0.000612             0.404624   \n",
       "4                 0.808081             0.000000             0.549133   \n",
       "...                    ...                  ...                  ...   \n",
       "66353             0.393939             0.000000             0.306358   \n",
       "66354             0.941414             0.000068             0.473988   \n",
       "66355             0.133333             0.002449             0.491329   \n",
       "66356             0.060606             0.000000             0.635838   \n",
       "66357             0.767677             0.000000             0.433526   \n",
       "\n",
       "       var:System_Air_Flow  \n",
       "0                   0.0225  \n",
       "1                   0.0000  \n",
       "2                   0.0000  \n",
       "3                   0.0000  \n",
       "4                   0.0000  \n",
       "...                    ...  \n",
       "66353               0.0025  \n",
       "66354               0.0150  \n",
       "66355               0.0000  \n",
       "66356               0.0000  \n",
       "66357               0.0000  \n",
       "\n",
       "[66358 rows x 124 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_1 (Dense)            (None, 100)               12500     \n",
      "_________________________________________________________________\n",
      "encoder_2 (Dense)            (None, 80)                8080      \n",
      "_________________________________________________________________\n",
      "encoder_3 (Dense)            (None, 60)                4860      \n",
      "_________________________________________________________________\n",
      "encoder_4 (Dense)            (None, 40)                2440      \n",
      "_________________________________________________________________\n",
      "code (Dense)                 (None, 20)                820       \n",
      "_________________________________________________________________\n",
      "decoder_1 (Dense)            (None, 40)                840       \n",
      "_________________________________________________________________\n",
      "decoder_2 (Dense)            (None, 60)                2460      \n",
      "_________________________________________________________________\n",
      "decoder_3 (Dense)            (None, 80)                4880      \n",
      "_________________________________________________________________\n",
      "decoder_4 (Dense)            (None, 100)               8100      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 124)               12524     \n",
      "=================================================================\n",
      "Total params: 57,504\n",
      "Trainable params: 57,504\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "autoencoder = Sequential()\n",
    "autoencoder.add(Dense(100, activation='relu', input_dim=input_dim, name='encoder_1'))\n",
    "autoencoder.add(Dense(80, activation='relu', name=\"encoder_2\"))\n",
    "autoencoder.add(Dense(60, activation='relu', name=\"encoder_3\"))\n",
    "autoencoder.add(Dense(40, activation='relu', name=\"encoder_4\"))\n",
    "autoencoder.add(Dense(20, activation='relu', name='code'))\n",
    "autoencoder.add(Dense(40, activation='relu', name=\"decoder_1\"))\n",
    "autoencoder.add(Dense(60, activation='relu', name=\"decoder_2\"))\n",
    "autoencoder.add(Dense(80, activation='relu', name=\"decoder_3\"))\n",
    "autoencoder.add(Dense(100, activation='relu', name=\"decoder_4\"))\n",
    "autoencoder.add(Dense(input_dim, activation='sigmoid', name='output'))\n",
    "autoencoder.compile(optimizer='adam', loss=\"mean_squared_error\")\n",
    "print(autoencoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_1 (Dense)            (None, 100)               12500     \n",
      "_________________________________________________________________\n",
      "encoder_2 (Dense)            (None, 80)                8080      \n",
      "_________________________________________________________________\n",
      "encoder_3 (Dense)            (None, 60)                4860      \n",
      "_________________________________________________________________\n",
      "encoder_4 (Dense)            (None, 40)                2440      \n",
      "_________________________________________________________________\n",
      "code (Dense)                 (None, 20)                820       \n",
      "_________________________________________________________________\n",
      "decoder_1 (Dense)            (None, 40)                840       \n",
      "_________________________________________________________________\n",
      "decoder_2 (Dense)            (None, 60)                2460      \n",
      "_________________________________________________________________\n",
      "decoder_3 (Dense)            (None, 80)                4880      \n",
      "_________________________________________________________________\n",
      "decoder_4 (Dense)            (None, 100)               8100      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 124)               12524     \n",
      "=================================================================\n",
      "Total params: 57,504\n",
      "Trainable params: 57,504\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 53086 samples, validate on 13272 samples\n",
      "Epoch 1/150\n",
      "53086/53086 [==============================] - 2s 37us/step - loss: 0.0137 - val_loss: 0.0065\n",
      "Epoch 2/150\n",
      "53086/53086 [==============================] - 2s 28us/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 3/150\n",
      "53086/53086 [==============================] - 1s 28us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 4/150\n",
      "53086/53086 [==============================] - 1s 26us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 5/150\n",
      "53086/53086 [==============================] - 1s 26us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 6/150\n",
      "53086/53086 [==============================] - 1s 26us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 7/150\n",
      "53086/53086 [==============================] - 1s 26us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 8/150\n",
      "53086/53086 [==============================] - 2s 30us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 9/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 10/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 11/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 12/150\n",
      "53086/53086 [==============================] - 2s 29us/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 13/150\n",
      "53086/53086 [==============================] - 2s 29us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 14/150\n",
      "53086/53086 [==============================] - 1s 28us/step - loss: 0.0011 - val_loss: 0.0023\n",
      "Epoch 15/150\n",
      "53086/53086 [==============================] - 1s 28us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 16/150\n",
      "53086/53086 [==============================] - 1s 28us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 17/150\n",
      "53086/53086 [==============================] - 1s 28us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 18/150\n",
      "53086/53086 [==============================] - 2s 29us/step - loss: 0.0010 - val_loss: 0.0020\n",
      "Epoch 19/150\n",
      "53086/53086 [==============================] - 2s 32us/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 20/150\n",
      "53086/53086 [==============================] - 2s 43us/step - loss: 9.9605e-04 - val_loss: 0.0021\n",
      "Epoch 21/150\n",
      "53086/53086 [==============================] - 2s 32us/step - loss: 9.7982e-04 - val_loss: 0.0019\n",
      "Epoch 22/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 9.5145e-04 - val_loss: 0.0018\n",
      "Epoch 23/150\n",
      "53086/53086 [==============================] - 2s 45us/step - loss: 9.3156e-04 - val_loss: 0.0019\n",
      "Epoch 24/150\n",
      "53086/53086 [==============================] - 2s 34us/step - loss: 9.1096e-04 - val_loss: 0.0017\n",
      "Epoch 25/150\n",
      "53086/53086 [==============================] - 2s 29us/step - loss: 8.9604e-04 - val_loss: 0.0018\n",
      "Epoch 26/150\n",
      "53086/53086 [==============================] - 2s 29us/step - loss: 8.7159e-04 - val_loss: 0.0017\n",
      "Epoch 27/150\n",
      "53086/53086 [==============================] - 2s 29us/step - loss: 8.5679e-04 - val_loss: 0.0017\n",
      "Epoch 28/150\n",
      "53086/53086 [==============================] - 2s 31us/step - loss: 8.4385e-04 - val_loss: 0.0017\n",
      "Epoch 29/150\n",
      "53086/53086 [==============================] - 2s 29us/step - loss: 8.2833e-04 - val_loss: 0.0016\n",
      "Epoch 30/150\n",
      "53086/53086 [==============================] - 2s 30us/step - loss: 8.1189e-04 - val_loss: 0.0016\n",
      "Epoch 31/150\n",
      "53086/53086 [==============================] - 1s 28us/step - loss: 7.9556e-04 - val_loss: 0.0016\n",
      "Epoch 32/150\n",
      "53086/53086 [==============================] - 1s 28us/step - loss: 7.8254e-04 - val_loss: 0.0016\n",
      "Epoch 33/150\n",
      "53086/53086 [==============================] - 1s 28us/step - loss: 7.7350e-04 - val_loss: 0.0016\n",
      "Epoch 34/150\n",
      "53086/53086 [==============================] - 1s 28us/step - loss: 7.6247e-04 - val_loss: 0.0016\n",
      "Epoch 35/150\n",
      "53086/53086 [==============================] - 1s 28us/step - loss: 7.5814e-04 - val_loss: 0.0015\n",
      "Epoch 36/150\n",
      "53086/53086 [==============================] - 1s 28us/step - loss: 7.3997e-04 - val_loss: 0.0016\n",
      "Epoch 37/150\n",
      "53086/53086 [==============================] - 1s 28us/step - loss: 7.3412e-04 - val_loss: 0.0017\n",
      "Epoch 38/150\n",
      "53086/53086 [==============================] - 2s 28us/step - loss: 7.2811e-04 - val_loss: 0.0017\n",
      "Epoch 39/150\n",
      "53086/53086 [==============================] - 1s 28us/step - loss: 7.2254e-04 - val_loss: 0.0017\n",
      "Epoch 40/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 7.0999e-04 - val_loss: 0.0017\n",
      "Epoch 41/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 7.1168e-04 - val_loss: 0.0016\n",
      "Epoch 42/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 6.9851e-04 - val_loss: 0.0017\n",
      "Epoch 43/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 6.9250e-04 - val_loss: 0.0018\n",
      "Epoch 44/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 6.9490e-04 - val_loss: 0.0016\n",
      "Epoch 45/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 6.8084e-04 - val_loss: 0.0017\n",
      "Epoch 46/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 6.7532e-04 - val_loss: 0.0017\n",
      "Epoch 47/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 6.7138e-04 - val_loss: 0.0016\n",
      "Epoch 48/150\n",
      "53086/53086 [==============================] - 2s 37us/step - loss: 6.6229e-04 - val_loss: 0.0016\n",
      "Epoch 49/150\n",
      "53086/53086 [==============================] - 2s 29us/step - loss: 6.5475e-04 - val_loss: 0.0015\n",
      "Epoch 50/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 6.4676e-04 - val_loss: 0.0015\n",
      "Epoch 51/150\n",
      "53086/53086 [==============================] - 1s 28us/step - loss: 6.4228e-04 - val_loss: 0.0016\n",
      "Epoch 52/150\n",
      "53086/53086 [==============================] - 1s 28us/step - loss: 6.3664e-04 - val_loss: 0.0016\n",
      "Epoch 53/150\n",
      "53086/53086 [==============================] - 1s 28us/step - loss: 6.2634e-04 - val_loss: 0.0015\n",
      "Epoch 54/150\n",
      "53086/53086 [==============================] - 2s 28us/step - loss: 6.2465e-04 - val_loss: 0.0015\n",
      "Epoch 55/150\n",
      "53086/53086 [==============================] - 2s 29us/step - loss: 6.1346e-04 - val_loss: 0.0015\n",
      "Epoch 56/150\n",
      "53086/53086 [==============================] - 2s 30us/step - loss: 6.0830e-04 - val_loss: 0.0015\n",
      "Epoch 57/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 6.0479e-04 - val_loss: 0.0016\n",
      "Epoch 58/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 5.9876e-04 - val_loss: 0.0016\n",
      "Epoch 59/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 5.9138e-04 - val_loss: 0.0015\n",
      "Epoch 60/150\n",
      "53086/53086 [==============================] - 2s 29us/step - loss: 5.8596e-04 - val_loss: 0.0016\n",
      "Epoch 61/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 5.8467e-04 - val_loss: 0.0015\n",
      "Epoch 62/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 5.7625e-04 - val_loss: 0.0017\n",
      "Epoch 63/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 6.1792e-04 - val_loss: 0.0015\n",
      "Epoch 64/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 5.6628e-04 - val_loss: 0.0014\n",
      "Epoch 65/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 5.6776e-04 - val_loss: 0.0014\n",
      "Epoch 66/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 5.6956e-04 - val_loss: 0.0014\n",
      "Epoch 67/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 5.6512e-04 - val_loss: 0.0014\n",
      "Epoch 68/150\n",
      "53086/53086 [==============================] - 1s 28us/step - loss: 5.5796e-04 - val_loss: 0.0017\n",
      "Epoch 69/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 5.5829e-04 - val_loss: 0.0014\n",
      "Epoch 70/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 5.7031e-04 - val_loss: 0.0014\n",
      "Epoch 71/150\n",
      "53086/53086 [==============================] - 2s 30us/step - loss: 5.5016e-04 - val_loss: 0.0015\n",
      "Epoch 72/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 5.5029e-04 - val_loss: 0.0015\n",
      "Epoch 73/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 5.4827e-04 - val_loss: 0.0014\n",
      "Epoch 74/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 5.4804e-04 - val_loss: 0.0015\n",
      "Epoch 75/150\n",
      "53086/53086 [==============================] - 2s 28us/step - loss: 5.4632e-04 - val_loss: 0.0014\n",
      "Epoch 76/150\n",
      "53086/53086 [==============================] - 1s 28us/step - loss: 5.4562e-04 - val_loss: 0.0016\n",
      "Epoch 77/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 5.4211e-04 - val_loss: 0.0019\n",
      "Epoch 78/150\n",
      "53086/53086 [==============================] - 2s 40us/step - loss: 5.3709e-04 - val_loss: 0.0014\n",
      "Epoch 79/150\n",
      "53086/53086 [==============================] - 2s 32us/step - loss: 5.4728e-04 - val_loss: 0.0014\n",
      "Epoch 80/150\n",
      "53086/53086 [==============================] - 1s 24us/step - loss: 5.3533e-04 - val_loss: 0.0017\n",
      "Epoch 81/150\n",
      "53086/53086 [==============================] - 2s 30us/step - loss: 5.3497e-04 - val_loss: 0.0015\n",
      "Epoch 82/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 5.2977e-04 - val_loss: 0.0017\n",
      "Epoch 83/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 5.3487e-04 - val_loss: 0.0014\n",
      "Epoch 84/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 5.3186e-04 - val_loss: 0.0015\n",
      "Epoch 85/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 5.2669e-04 - val_loss: 0.0017\n",
      "Epoch 86/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 5.2964e-04 - val_loss: 0.0015\n",
      "Epoch 87/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 5.2535e-04 - val_loss: 0.0016\n",
      "Epoch 88/150\n",
      "53086/53086 [==============================] - 2s 29us/step - loss: 5.2350e-04 - val_loss: 0.0015\n",
      "Epoch 89/150\n",
      "53086/53086 [==============================] - 1s 28us/step - loss: 5.2269e-04 - val_loss: 0.0014\n",
      "Epoch 90/150\n",
      "53086/53086 [==============================] - 1s 28us/step - loss: 5.2272e-04 - val_loss: 0.0018\n",
      "Epoch 91/150\n",
      "53086/53086 [==============================] - 1s 28us/step - loss: 5.4598e-04 - val_loss: 0.0013\n",
      "Epoch 92/150\n",
      "53086/53086 [==============================] - 2s 29us/step - loss: 5.1641e-04 - val_loss: 0.0014\n",
      "Epoch 93/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 5.1567e-04 - val_loss: 0.0015\n",
      "Epoch 94/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 5.1321e-04 - val_loss: 0.0014\n",
      "Epoch 95/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 5.1417e-04 - val_loss: 0.0016\n",
      "Epoch 96/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 5.1435e-04 - val_loss: 0.0016\n",
      "Epoch 97/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 5.1940e-04 - val_loss: 0.0017\n",
      "Epoch 98/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 5.0961e-04 - val_loss: 0.0017\n",
      "Epoch 99/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 5.0911e-04 - val_loss: 0.0016\n",
      "Epoch 100/150\n",
      "53086/53086 [==============================] - 2s 31us/step - loss: 5.1027e-04 - val_loss: 0.0018\n",
      "Epoch 101/150\n",
      "53086/53086 [==============================] - 2s 34us/step - loss: 5.0923e-04 - val_loss: 0.0019\n",
      "Epoch 102/150\n",
      "53086/53086 [==============================] - 2s 28us/step - loss: 5.1375e-04 - val_loss: 0.0015\n",
      "Epoch 103/150\n",
      "53086/53086 [==============================] - 3s 50us/step - loss: 5.0563e-04 - val_loss: 0.0016\n",
      "Epoch 104/150\n",
      "53086/53086 [==============================] - 1s 24us/step - loss: 5.0263e-04 - val_loss: 0.0017\n",
      "Epoch 105/150\n",
      "53086/53086 [==============================] - 2s 31us/step - loss: 5.0304e-04 - val_loss: 0.0017\n",
      "Epoch 106/150\n",
      "53086/53086 [==============================] - 2s 32us/step - loss: 6.3801e-04 - val_loss: 0.0012\n",
      "Epoch 107/150\n",
      "53086/53086 [==============================] - 1s 28us/step - loss: 4.9637e-04 - val_loss: 0.0013\n",
      "Epoch 108/150\n",
      "53086/53086 [==============================] - 2s 28us/step - loss: 4.9713e-04 - val_loss: 0.0014\n",
      "Epoch 109/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 4.9737e-04 - val_loss: 0.0016\n",
      "Epoch 110/150\n",
      "53086/53086 [==============================] - 2s 28us/step - loss: 5.0075e-04 - val_loss: 0.0017\n",
      "Epoch 111/150\n",
      "53086/53086 [==============================] - 1s 27us/step - loss: 4.9458e-04 - val_loss: 0.0016\n",
      "Epoch 112/150\n",
      "53086/53086 [==============================] - 2s 33us/step - loss: 5.0354e-04 - val_loss: 0.0013\n",
      "Epoch 113/150\n",
      "53086/53086 [==============================] - 2s 30us/step - loss: 4.8917e-04 - val_loss: 0.0014\n",
      "Epoch 114/150\n",
      "53086/53086 [==============================] - 2s 28us/step - loss: 4.9426e-04 - val_loss: 0.0015\n",
      "Epoch 115/150\n",
      "53086/53086 [==============================] - 1s 28us/step - loss: 4.9127e-04 - val_loss: 0.0017\n",
      "Epoch 116/150\n",
      "53086/53086 [==============================] - 1s 28us/step - loss: 4.8427e-04 - val_loss: 0.0016\n",
      "Epoch 117/150\n",
      "53086/53086 [==============================] - 2s 30us/step - loss: 4.8122e-04 - val_loss: 0.0017\n",
      "Epoch 118/150\n",
      "53086/53086 [==============================] - 2s 32us/step - loss: 5.4571e-04 - val_loss: 0.0012\n",
      "Epoch 119/150\n",
      "53086/53086 [==============================] - 2s 34us/step - loss: 4.7601e-04 - val_loss: 0.0012\n",
      "Epoch 120/150\n",
      "53086/53086 [==============================] - 3s 48us/step - loss: 4.7653e-04 - val_loss: 0.0013\n",
      "Epoch 121/150\n",
      "53086/53086 [==============================] - 2s 32us/step - loss: 4.7777e-04 - val_loss: 0.0014\n",
      "Epoch 122/150\n",
      "53086/53086 [==============================] - 3s 48us/step - loss: 4.7611e-04 - val_loss: 0.0015\n",
      "Epoch 123/150\n",
      "53086/53086 [==============================] - 2s 36us/step - loss: 4.8471e-04 - val_loss: 0.0014\n",
      "Epoch 124/150\n",
      "53086/53086 [==============================] - 2s 44us/step - loss: 4.7205e-04 - val_loss: 0.0016\n",
      "Epoch 125/150\n",
      "53086/53086 [==============================] - 3s 53us/step - loss: 4.7075e-04 - val_loss: 0.0015\n",
      "Epoch 126/150\n",
      "53086/53086 [==============================] - 2s 32us/step - loss: 4.7706e-04 - val_loss: 0.0014\n",
      "Epoch 127/150\n",
      "53086/53086 [==============================] - 2s 30us/step - loss: 4.6857e-04 - val_loss: 0.0015\n",
      "Epoch 128/150\n",
      "53086/53086 [==============================] - 2s 29us/step - loss: 4.6969e-04 - val_loss: 0.0018\n",
      "Epoch 129/150\n",
      "53086/53086 [==============================] - 2s 29us/step - loss: 4.6822e-04 - val_loss: 0.0017\n",
      "Epoch 130/150\n",
      "53086/53086 [==============================] - 2s 36us/step - loss: 4.6558e-04 - val_loss: 0.0017\n",
      "Epoch 131/150\n",
      "53086/53086 [==============================] - 2s 31us/step - loss: 5.2495e-04 - val_loss: 0.0012\n",
      "Epoch 132/150\n",
      "53086/53086 [==============================] - 2s 33us/step - loss: 4.6132e-04 - val_loss: 0.0012\n",
      "Epoch 133/150\n",
      "53086/53086 [==============================] - 2s 33us/step - loss: 4.6014e-04 - val_loss: 0.0012\n",
      "Epoch 134/150\n",
      "53086/53086 [==============================] - 2s 34us/step - loss: 4.6172e-04 - val_loss: 0.0014\n",
      "Epoch 135/150\n",
      "53086/53086 [==============================] - 2s 33us/step - loss: 5.7543e-04 - val_loss: 0.0011\n",
      "Epoch 136/150\n",
      "53086/53086 [==============================] - 2s 32us/step - loss: 4.5654e-04 - val_loss: 0.0011\n",
      "Epoch 137/150\n",
      "53086/53086 [==============================] - 2s 32us/step - loss: 4.5666e-04 - val_loss: 0.0011\n",
      "Epoch 138/150\n",
      "53086/53086 [==============================] - 2s 32us/step - loss: 4.5825e-04 - val_loss: 0.0011\n",
      "Epoch 139/150\n",
      "53086/53086 [==============================] - 2s 35us/step - loss: 4.5640e-04 - val_loss: 0.0013\n",
      "Epoch 140/150\n",
      "53086/53086 [==============================] - 2s 32us/step - loss: 4.6541e-04 - val_loss: 0.0013\n",
      "Epoch 141/150\n",
      "53086/53086 [==============================] - 2s 32us/step - loss: 4.5581e-04 - val_loss: 0.0013\n",
      "Epoch 142/150\n",
      "53086/53086 [==============================] - 2s 32us/step - loss: 4.5463e-04 - val_loss: 0.0012\n",
      "Epoch 143/150\n",
      "53086/53086 [==============================] - 2s 32us/step - loss: 4.5472e-04 - val_loss: 0.0015\n",
      "Epoch 144/150\n",
      "53086/53086 [==============================] - 2s 32us/step - loss: 4.9047e-04 - val_loss: 0.0015\n",
      "Epoch 145/150\n",
      "53086/53086 [==============================] - 2s 31us/step - loss: 4.4798e-04 - val_loss: 0.0013\n",
      "Epoch 146/150\n",
      "53086/53086 [==============================] - 2s 31us/step - loss: 4.4800e-04 - val_loss: 0.0014\n",
      "Epoch 147/150\n",
      "53086/53086 [==============================] - 2s 32us/step - loss: 4.5221e-04 - val_loss: 0.0016\n",
      "Epoch 148/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53086/53086 [==============================] - 2s 31us/step - loss: 4.4853e-04 - val_loss: 0.0015\n",
      "Epoch 149/150\n",
      "53086/53086 [==============================] - 2s 30us/step - loss: 4.4893e-04 - val_loss: 0.0017\n",
      "Epoch 150/150\n",
      "53086/53086 [==============================] - 2s 29us/step - loss: 4.5144e-04 - val_loss: 0.0015\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(x=input_data, y=input_data, epochs=150, validation_split=0.20, batch_size=75,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-315fe873894a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot training & validation loss values\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.savefig(\"./img/loss_autoencoder_history.png\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66358/66358 [==============================] - 1s 12us/step\n",
      "0.0006683709033869009\n"
     ]
    }
   ],
   "source": [
    "loss = autoencoder.evaluate(input_data, input_data)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save('./models/my_models/autoencoder_model03.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = load_model('./models/my_models/autoencoder_model03.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder (Model)              (None, 20)                28700     \n",
      "_________________________________________________________________\n",
      "hidden (Dense)               (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 29,141\n",
      "Trainable params: 441\n",
      "Non-trainable params: 28,700\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#classifier model\n",
    "encoder = Model(inputs=autoencoder.get_layer(\"encoder_1\").input, outputs=autoencoder.get_layer(\"code\").output)\n",
    "classifier = Sequential()\n",
    "classifier.add(encoder)\n",
    "classifier.add(Dense(20, activation='relu', name=\"hidden\"))\n",
    "classifier.add(Dense(1,activation=\"sigmoid\", name=\"output\"))\n",
    "classifier.layers[0].name=\"encoder\"\n",
    "classifier.layers[0].trainable=False\n",
    "classifier.compile(optimizer='adam', loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "print(classifier.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 59722 samples, validate on 6636 samples\n",
      "Epoch 1/150\n",
      "59722/59722 [==============================] - 1s 17us/step - loss: 0.0974 - accuracy: 0.9743 - val_loss: 0.0742 - val_accuracy: 0.9837\n",
      "Epoch 2/150\n",
      "59722/59722 [==============================] - 1s 17us/step - loss: 0.0653 - accuracy: 0.9806 - val_loss: 0.0700 - val_accuracy: 0.9840\n",
      "Epoch 3/150\n",
      "59722/59722 [==============================] - 1s 20us/step - loss: 0.0611 - accuracy: 0.9834 - val_loss: 0.0654 - val_accuracy: 0.9851\n",
      "Epoch 4/150\n",
      "59722/59722 [==============================] - 1s 15us/step - loss: 0.0585 - accuracy: 0.9850 - val_loss: 0.0648 - val_accuracy: 0.9849\n",
      "Epoch 5/150\n",
      "59722/59722 [==============================] - 1s 15us/step - loss: 0.0573 - accuracy: 0.9854 - val_loss: 0.0623 - val_accuracy: 0.9860\n",
      "Epoch 6/150\n",
      "59722/59722 [==============================] - 1s 16us/step - loss: 0.0563 - accuracy: 0.9857 - val_loss: 0.0604 - val_accuracy: 0.9848\n",
      "Epoch 7/150\n",
      "59722/59722 [==============================] - 1s 16us/step - loss: 0.0553 - accuracy: 0.9860 - val_loss: 0.0593 - val_accuracy: 0.9843\n",
      "Epoch 8/150\n",
      "59722/59722 [==============================] - 1s 18us/step - loss: 0.0544 - accuracy: 0.9859 - val_loss: 0.0586 - val_accuracy: 0.9845\n",
      "Epoch 9/150\n",
      "59722/59722 [==============================] - 1s 19us/step - loss: 0.0535 - accuracy: 0.9864 - val_loss: 0.0583 - val_accuracy: 0.9848\n",
      "Epoch 10/150\n",
      "59722/59722 [==============================] - 1s 16us/step - loss: 0.0528 - accuracy: 0.9864 - val_loss: 0.0582 - val_accuracy: 0.9848\n",
      "Epoch 11/150\n",
      "59722/59722 [==============================] - 1s 16us/step - loss: 0.0523 - accuracy: 0.9862 - val_loss: 0.0585 - val_accuracy: 0.9852\n",
      "Epoch 12/150\n",
      "59722/59722 [==============================] - 1s 15us/step - loss: 0.0513 - accuracy: 0.9866 - val_loss: 0.0575 - val_accuracy: 0.9845\n",
      "Epoch 13/150\n",
      "59722/59722 [==============================] - 1s 15us/step - loss: 0.0509 - accuracy: 0.9864 - val_loss: 0.0585 - val_accuracy: 0.9845\n",
      "Epoch 14/150\n",
      "59722/59722 [==============================] - 1s 15us/step - loss: 0.0504 - accuracy: 0.9866 - val_loss: 0.0602 - val_accuracy: 0.9840\n",
      "Epoch 15/150\n",
      "59722/59722 [==============================] - 1s 15us/step - loss: 0.0499 - accuracy: 0.9865 - val_loss: 0.0575 - val_accuracy: 0.9846\n",
      "Epoch 16/150\n",
      "59722/59722 [==============================] - 1s 16us/step - loss: 0.0491 - accuracy: 0.9865 - val_loss: 0.0576 - val_accuracy: 0.9845\n",
      "Epoch 17/150\n",
      "59722/59722 [==============================] - 1s 15us/step - loss: 0.0491 - accuracy: 0.9866 - val_loss: 0.0572 - val_accuracy: 0.9843\n",
      "Epoch 18/150\n",
      "59722/59722 [==============================] - 1s 15us/step - loss: 0.0485 - accuracy: 0.9866 - val_loss: 0.0565 - val_accuracy: 0.9843\n",
      "Epoch 19/150\n",
      "59722/59722 [==============================] - 1s 20us/step - loss: 0.0483 - accuracy: 0.9865 - val_loss: 0.0572 - val_accuracy: 0.9842\n",
      "Epoch 20/150\n",
      "59722/59722 [==============================] - 1s 22us/step - loss: 0.0475 - accuracy: 0.9868 - val_loss: 0.0568 - val_accuracy: 0.9845\n",
      "Epoch 21/150\n",
      "59722/59722 [==============================] - 1s 16us/step - loss: 0.0472 - accuracy: 0.9870 - val_loss: 0.0571 - val_accuracy: 0.9837\n",
      "Epoch 22/150\n",
      "59722/59722 [==============================] - 1s 19us/step - loss: 0.0473 - accuracy: 0.9867 - val_loss: 0.0577 - val_accuracy: 0.9836\n",
      "Epoch 23/150\n",
      "59722/59722 [==============================] - 1s 20us/step - loss: 0.0469 - accuracy: 0.9869 - val_loss: 0.0563 - val_accuracy: 0.9848\n",
      "Epoch 24/150\n",
      "59722/59722 [==============================] - 1s 18us/step - loss: 0.0464 - accuracy: 0.9870 - val_loss: 0.0558 - val_accuracy: 0.9849\n",
      "Epoch 25/150\n",
      "59722/59722 [==============================] - 1s 16us/step - loss: 0.0459 - accuracy: 0.9869 - val_loss: 0.0568 - val_accuracy: 0.9836\n",
      "Epoch 26/150\n",
      "59722/59722 [==============================] - 1s 14us/step - loss: 0.0460 - accuracy: 0.9869 - val_loss: 0.0568 - val_accuracy: 0.9848\n",
      "Epoch 27/150\n",
      "59722/59722 [==============================] - 1s 14us/step - loss: 0.0458 - accuracy: 0.9868 - val_loss: 0.0566 - val_accuracy: 0.9845\n",
      "Epoch 28/150\n",
      "59722/59722 [==============================] - 1s 13us/step - loss: 0.0453 - accuracy: 0.9870 - val_loss: 0.0584 - val_accuracy: 0.9815\n",
      "Epoch 29/150\n",
      "59722/59722 [==============================] - 1s 13us/step - loss: 0.0451 - accuracy: 0.9870 - val_loss: 0.0567 - val_accuracy: 0.9843\n",
      "Epoch 30/150\n",
      "59722/59722 [==============================] - 1s 12us/step - loss: 0.0449 - accuracy: 0.9871 - val_loss: 0.0572 - val_accuracy: 0.9840\n",
      "Epoch 31/150\n",
      "59722/59722 [==============================] - 1s 13us/step - loss: 0.0444 - accuracy: 0.9872 - val_loss: 0.0578 - val_accuracy: 0.9845\n",
      "Epoch 32/150\n",
      "59722/59722 [==============================] - 1s 13us/step - loss: 0.0445 - accuracy: 0.9870 - val_loss: 0.0571 - val_accuracy: 0.9848\n",
      "Epoch 33/150\n",
      "59722/59722 [==============================] - 1s 12us/step - loss: 0.0440 - accuracy: 0.9871 - val_loss: 0.0574 - val_accuracy: 0.9825\n",
      "Epoch 34/150\n",
      "59722/59722 [==============================] - 1s 12us/step - loss: 0.0439 - accuracy: 0.9870 - val_loss: 0.0564 - val_accuracy: 0.9839\n",
      "Epoch 35/150\n",
      "59722/59722 [==============================] - 1s 12us/step - loss: 0.0439 - accuracy: 0.9872 - val_loss: 0.0568 - val_accuracy: 0.9833\n",
      "Epoch 36/150\n",
      "59722/59722 [==============================] - 1s 13us/step - loss: 0.0435 - accuracy: 0.9873 - val_loss: 0.0589 - val_accuracy: 0.9819\n",
      "Epoch 37/150\n",
      "59722/59722 [==============================] - 1s 13us/step - loss: 0.0435 - accuracy: 0.9872 - val_loss: 0.0582 - val_accuracy: 0.9822\n",
      "Epoch 38/150\n",
      "59722/59722 [==============================] - 1s 13us/step - loss: 0.0432 - accuracy: 0.9872 - val_loss: 0.0592 - val_accuracy: 0.9816\n",
      "Epoch 39/150\n",
      "59722/59722 [==============================] - 1s 14us/step - loss: 0.0427 - accuracy: 0.9874 - val_loss: 0.0599 - val_accuracy: 0.9804\n",
      "Epoch 40/150\n",
      "59722/59722 [==============================] - 1s 13us/step - loss: 0.0425 - accuracy: 0.9874 - val_loss: 0.0583 - val_accuracy: 0.9824\n",
      "Epoch 41/150\n",
      "59722/59722 [==============================] - 1s 13us/step - loss: 0.0421 - accuracy: 0.9873 - val_loss: 0.0582 - val_accuracy: 0.9824\n",
      "Epoch 42/150\n",
      "59722/59722 [==============================] - 1s 13us/step - loss: 0.0422 - accuracy: 0.9873 - val_loss: 0.0591 - val_accuracy: 0.9824\n",
      "Epoch 43/150\n",
      "59722/59722 [==============================] - 1s 13us/step - loss: 0.0418 - accuracy: 0.9877 - val_loss: 0.0648 - val_accuracy: 0.9786\n",
      "Epoch 44/150\n",
      "59722/59722 [==============================] - 1s 13us/step - loss: 0.0417 - accuracy: 0.9878 - val_loss: 0.0599 - val_accuracy: 0.9816\n",
      "Epoch 45/150\n",
      "59722/59722 [==============================] - 1s 12us/step - loss: 0.0414 - accuracy: 0.9876 - val_loss: 0.0586 - val_accuracy: 0.9836\n",
      "Epoch 46/150\n",
      "59722/59722 [==============================] - 1s 13us/step - loss: 0.0413 - accuracy: 0.9877 - val_loss: 0.0589 - val_accuracy: 0.9834\n",
      "Epoch 47/150\n",
      "59722/59722 [==============================] - 1s 12us/step - loss: 0.0409 - accuracy: 0.9879 - val_loss: 0.0584 - val_accuracy: 0.9839\n",
      "Epoch 48/150\n",
      "59722/59722 [==============================] - 1s 12us/step - loss: 0.0407 - accuracy: 0.9879 - val_loss: 0.0596 - val_accuracy: 0.9825\n",
      "Epoch 49/150\n",
      "59722/59722 [==============================] - 1s 12us/step - loss: 0.0403 - accuracy: 0.9880 - val_loss: 0.0613 - val_accuracy: 0.9813\n",
      "Epoch 50/150\n",
      "59722/59722 [==============================] - 1s 13us/step - loss: 0.0402 - accuracy: 0.9879 - val_loss: 0.0611 - val_accuracy: 0.9822\n",
      "Epoch 51/150\n",
      "59722/59722 [==============================] - 1s 13us/step - loss: 0.0401 - accuracy: 0.9879 - val_loss: 0.0619 - val_accuracy: 0.9807\n",
      "Epoch 52/150\n",
      "59722/59722 [==============================] - 1s 13us/step - loss: 0.0399 - accuracy: 0.9880 - val_loss: 0.0591 - val_accuracy: 0.9848\n",
      "Epoch 53/150\n",
      "59722/59722 [==============================] - 1s 13us/step - loss: 0.0396 - accuracy: 0.9880 - val_loss: 0.0621 - val_accuracy: 0.9810\n",
      "Epoch 54/150\n",
      "59722/59722 [==============================] - 1s 12us/step - loss: 0.0396 - accuracy: 0.9880 - val_loss: 0.0595 - val_accuracy: 0.9840\n",
      "Epoch 55/150\n",
      "59722/59722 [==============================] - 1s 12us/step - loss: 0.0394 - accuracy: 0.9881 - val_loss: 0.0606 - val_accuracy: 0.9836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/150\n",
      "59722/59722 [==============================] - 1s 12us/step - loss: 0.0391 - accuracy: 0.9882 - val_loss: 0.0668 - val_accuracy: 0.9798\n",
      "Epoch 57/150\n",
      "59722/59722 [==============================] - 1s 13us/step - loss: 0.0393 - accuracy: 0.9882 - val_loss: 0.0594 - val_accuracy: 0.9840\n",
      "Epoch 58/150\n",
      "59722/59722 [==============================] - 1s 13us/step - loss: 0.0389 - accuracy: 0.9881 - val_loss: 0.0634 - val_accuracy: 0.9798\n",
      "Epoch 59/150\n",
      "59722/59722 [==============================] - 1s 13us/step - loss: 0.0391 - accuracy: 0.9882 - val_loss: 0.0575 - val_accuracy: 0.9842\n",
      "Epoch 60/150\n",
      "59722/59722 [==============================] - 1s 13us/step - loss: 0.0385 - accuracy: 0.9883 - val_loss: 0.0584 - val_accuracy: 0.9854\n",
      "Epoch 61/150\n",
      "59722/59722 [==============================] - 1s 17us/step - loss: 0.0386 - accuracy: 0.9883 - val_loss: 0.0588 - val_accuracy: 0.9848\n",
      "Epoch 62/150\n",
      "59722/59722 [==============================] - 1s 16us/step - loss: 0.0381 - accuracy: 0.9879 - val_loss: 0.0588 - val_accuracy: 0.9849\n",
      "Epoch 63/150\n",
      "59722/59722 [==============================] - 1s 14us/step - loss: 0.0383 - accuracy: 0.9885 - val_loss: 0.0617 - val_accuracy: 0.9842\n",
      "Epoch 64/150\n",
      "59722/59722 [==============================] - 1s 17us/step - loss: 0.0379 - accuracy: 0.9885 - val_loss: 0.0592 - val_accuracy: 0.9848\n",
      "Epoch 65/150\n",
      "59722/59722 [==============================] - 1s 17us/step - loss: 0.0379 - accuracy: 0.9883 - val_loss: 0.0624 - val_accuracy: 0.9810\n",
      "Epoch 66/150\n",
      "59722/59722 [==============================] - 1s 21us/step - loss: 0.0379 - accuracy: 0.9882 - val_loss: 0.0628 - val_accuracy: 0.9819\n",
      "Epoch 67/150\n",
      "59722/59722 [==============================] - 1s 14us/step - loss: 0.0374 - accuracy: 0.9885 - val_loss: 0.0602 - val_accuracy: 0.9861\n",
      "Epoch 68/150\n",
      "59722/59722 [==============================] - 1s 14us/step - loss: 0.0377 - accuracy: 0.9885 - val_loss: 0.0572 - val_accuracy: 0.9857\n",
      "Epoch 69/150\n",
      "59722/59722 [==============================] - 1s 14us/step - loss: 0.0375 - accuracy: 0.9884 - val_loss: 0.0582 - val_accuracy: 0.9857\n",
      "Epoch 70/150\n",
      "59722/59722 [==============================] - 1s 24us/step - loss: 0.0376 - accuracy: 0.9885 - val_loss: 0.0587 - val_accuracy: 0.9858\n",
      "Epoch 71/150\n",
      "59722/59722 [==============================] - 1s 22us/step - loss: 0.0371 - accuracy: 0.9886 - val_loss: 0.0591 - val_accuracy: 0.9858\n",
      "Epoch 72/150\n",
      "59722/59722 [==============================] - 1s 20us/step - loss: 0.0371 - accuracy: 0.9889 - val_loss: 0.0622 - val_accuracy: 0.9825\n",
      "Epoch 73/150\n",
      "59722/59722 [==============================] - 1s 15us/step - loss: 0.0370 - accuracy: 0.9887 - val_loss: 0.0592 - val_accuracy: 0.9849\n",
      "Epoch 74/150\n",
      "59722/59722 [==============================] - 1s 15us/step - loss: 0.0370 - accuracy: 0.9886 - val_loss: 0.0617 - val_accuracy: 0.9834\n",
      "Epoch 75/150\n",
      "59722/59722 [==============================] - 1s 21us/step - loss: 0.0373 - accuracy: 0.9885 - val_loss: 0.0600 - val_accuracy: 0.9834\n",
      "Epoch 76/150\n",
      "59722/59722 [==============================] - 1s 16us/step - loss: 0.0369 - accuracy: 0.9889 - val_loss: 0.0573 - val_accuracy: 0.9863\n",
      "Epoch 77/150\n",
      "59722/59722 [==============================] - 1s 15us/step - loss: 0.0369 - accuracy: 0.9888 - val_loss: 0.0590 - val_accuracy: 0.9851\n",
      "Epoch 78/150\n",
      "59722/59722 [==============================] - 1s 14us/step - loss: 0.0369 - accuracy: 0.9885 - val_loss: 0.0580 - val_accuracy: 0.9861\n",
      "Epoch 79/150\n",
      "59722/59722 [==============================] - 1s 16us/step - loss: 0.0368 - accuracy: 0.9888 - val_loss: 0.0587 - val_accuracy: 0.9854\n",
      "Epoch 80/150\n",
      "59722/59722 [==============================] - 1s 14us/step - loss: 0.0366 - accuracy: 0.9889 - val_loss: 0.0578 - val_accuracy: 0.9861\n",
      "Epoch 81/150\n",
      "59722/59722 [==============================] - 1s 16us/step - loss: 0.0368 - accuracy: 0.9885 - val_loss: 0.0575 - val_accuracy: 0.9870\n",
      "Epoch 82/150\n",
      "59722/59722 [==============================] - 1s 17us/step - loss: 0.0364 - accuracy: 0.9886 - val_loss: 0.0579 - val_accuracy: 0.9863\n",
      "Epoch 83/150\n",
      "59722/59722 [==============================] - 1s 19us/step - loss: 0.0363 - accuracy: 0.9887 - val_loss: 0.0611 - val_accuracy: 0.9822\n",
      "Epoch 84/150\n",
      "59722/59722 [==============================] - 1s 15us/step - loss: 0.0363 - accuracy: 0.9889 - val_loss: 0.0575 - val_accuracy: 0.9851\n",
      "Epoch 85/150\n",
      "59722/59722 [==============================] - 1s 15us/step - loss: 0.0361 - accuracy: 0.9888 - val_loss: 0.0577 - val_accuracy: 0.9860\n",
      "Epoch 86/150\n",
      "59722/59722 [==============================] - 1s 16us/step - loss: 0.0363 - accuracy: 0.9888 - val_loss: 0.0570 - val_accuracy: 0.9872\n",
      "Epoch 87/150\n",
      "59722/59722 [==============================] - 1s 17us/step - loss: 0.0367 - accuracy: 0.9887 - val_loss: 0.0580 - val_accuracy: 0.9860\n",
      "Epoch 88/150\n",
      "59722/59722 [==============================] - 1s 16us/step - loss: 0.0362 - accuracy: 0.9888 - val_loss: 0.0579 - val_accuracy: 0.9846\n",
      "Epoch 89/150\n",
      "59722/59722 [==============================] - 1s 15us/step - loss: 0.0362 - accuracy: 0.9890 - val_loss: 0.0594 - val_accuracy: 0.9855\n",
      "Epoch 90/150\n",
      "59722/59722 [==============================] - 1s 16us/step - loss: 0.0360 - accuracy: 0.9888 - val_loss: 0.0589 - val_accuracy: 0.9860\n",
      "Epoch 91/150\n",
      "59722/59722 [==============================] - 1s 16us/step - loss: 0.0360 - accuracy: 0.9891 - val_loss: 0.0571 - val_accuracy: 0.9863\n",
      "Epoch 92/150\n",
      "59722/59722 [==============================] - 1s 18us/step - loss: 0.0364 - accuracy: 0.9888 - val_loss: 0.0567 - val_accuracy: 0.9858\n",
      "Epoch 93/150\n",
      "59722/59722 [==============================] - 1s 15us/step - loss: 0.0358 - accuracy: 0.9890 - val_loss: 0.0589 - val_accuracy: 0.9849\n",
      "Epoch 94/150\n",
      "59722/59722 [==============================] - 1s 16us/step - loss: 0.0360 - accuracy: 0.9889 - val_loss: 0.0585 - val_accuracy: 0.9861\n",
      "Epoch 95/150\n",
      "59722/59722 [==============================] - 1s 16us/step - loss: 0.0358 - accuracy: 0.9891 - val_loss: 0.0568 - val_accuracy: 0.9858\n",
      "Epoch 96/150\n",
      "59722/59722 [==============================] - 1s 15us/step - loss: 0.0357 - accuracy: 0.9892 - val_loss: 0.0578 - val_accuracy: 0.9855\n",
      "Epoch 97/150\n",
      "59722/59722 [==============================] - 1s 15us/step - loss: 0.0360 - accuracy: 0.9890 - val_loss: 0.0579 - val_accuracy: 0.9866\n",
      "Epoch 98/150\n",
      "59722/59722 [==============================] - 1s 14us/step - loss: 0.0357 - accuracy: 0.9887 - val_loss: 0.0595 - val_accuracy: 0.9836\n",
      "Epoch 99/150\n",
      "59722/59722 [==============================] - 1s 15us/step - loss: 0.0355 - accuracy: 0.9892 - val_loss: 0.0621 - val_accuracy: 0.9851\n",
      "Epoch 100/150\n",
      "59722/59722 [==============================] - 1s 18us/step - loss: 0.0355 - accuracy: 0.9890 - val_loss: 0.0589 - val_accuracy: 0.9848\n",
      "Epoch 101/150\n",
      "59722/59722 [==============================] - 1s 18us/step - loss: 0.0354 - accuracy: 0.9892 - val_loss: 0.0577 - val_accuracy: 0.9855\n",
      "Epoch 102/150\n",
      "59722/59722 [==============================] - 1s 15us/step - loss: 0.0353 - accuracy: 0.9893 - val_loss: 0.0575 - val_accuracy: 0.9861\n",
      "Epoch 103/150\n",
      "59722/59722 [==============================] - 1s 15us/step - loss: 0.0358 - accuracy: 0.9892 - val_loss: 0.0636 - val_accuracy: 0.9852\n",
      "Epoch 104/150\n",
      "59722/59722 [==============================] - 1s 15us/step - loss: 0.0355 - accuracy: 0.9892 - val_loss: 0.0584 - val_accuracy: 0.9854\n",
      "Epoch 105/150\n",
      "59722/59722 [==============================] - 1s 15us/step - loss: 0.0356 - accuracy: 0.9891 - val_loss: 0.0589 - val_accuracy: 0.9851\n",
      "Epoch 106/150\n",
      "59722/59722 [==============================] - 1s 15us/step - loss: 0.0354 - accuracy: 0.9893 - val_loss: 0.0582 - val_accuracy: 0.9846\n",
      "Epoch 107/150\n",
      "59722/59722 [==============================] - 1s 16us/step - loss: 0.0352 - accuracy: 0.9891 - val_loss: 0.0577 - val_accuracy: 0.9861\n",
      "Epoch 108/150\n",
      "59722/59722 [==============================] - 1s 20us/step - loss: 0.0354 - accuracy: 0.9892 - val_loss: 0.0601 - val_accuracy: 0.9840\n",
      "Epoch 109/150\n",
      "59722/59722 [==============================] - 1s 18us/step - loss: 0.0352 - accuracy: 0.9893 - val_loss: 0.0584 - val_accuracy: 0.9849\n",
      "Epoch 110/150\n",
      "59722/59722 [==============================] - 1s 15us/step - loss: 0.0351 - accuracy: 0.9893 - val_loss: 0.0576 - val_accuracy: 0.9861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/150\n",
      "59722/59722 [==============================] - 1s 14us/step - loss: 0.0352 - accuracy: 0.9890 - val_loss: 0.0586 - val_accuracy: 0.9861\n",
      "Epoch 112/150\n",
      "59722/59722 [==============================] - 1s 19us/step - loss: 0.0352 - accuracy: 0.9892 - val_loss: 0.0621 - val_accuracy: 0.9834\n",
      "Epoch 113/150\n",
      "59722/59722 [==============================] - 1s 16us/step - loss: 0.0353 - accuracy: 0.9894 - val_loss: 0.0593 - val_accuracy: 0.9852\n",
      "Epoch 114/150\n",
      "59722/59722 [==============================] - 1s 21us/step - loss: 0.0349 - accuracy: 0.9892 - val_loss: 0.0569 - val_accuracy: 0.9861\n",
      "Epoch 115/150\n",
      "59722/59722 [==============================] - 1s 20us/step - loss: 0.0351 - accuracy: 0.9893 - val_loss: 0.0582 - val_accuracy: 0.9864\n",
      "Epoch 116/150\n",
      "59722/59722 [==============================] - 1s 20us/step - loss: 0.0350 - accuracy: 0.9894 - val_loss: 0.0579 - val_accuracy: 0.9864\n",
      "Epoch 117/150\n",
      "59722/59722 [==============================] - 1s 13us/step - loss: 0.0352 - accuracy: 0.9890 - val_loss: 0.0618 - val_accuracy: 0.9833\n",
      "Epoch 118/150\n",
      "59722/59722 [==============================] - 1s 20us/step - loss: 0.0353 - accuracy: 0.9890 - val_loss: 0.0599 - val_accuracy: 0.9846\n",
      "Epoch 119/150\n",
      "59722/59722 [==============================] - 1s 20us/step - loss: 0.0352 - accuracy: 0.9893 - val_loss: 0.0603 - val_accuracy: 0.9840\n",
      "Epoch 120/150\n",
      "59722/59722 [==============================] - 1s 14us/step - loss: 0.0348 - accuracy: 0.9894 - val_loss: 0.0604 - val_accuracy: 0.9849\n",
      "Epoch 121/150\n",
      "59722/59722 [==============================] - 1s 23us/step - loss: 0.0349 - accuracy: 0.9891 - val_loss: 0.0609 - val_accuracy: 0.9840\n",
      "Epoch 122/150\n",
      "59722/59722 [==============================] - 1s 17us/step - loss: 0.0349 - accuracy: 0.9894 - val_loss: 0.0587 - val_accuracy: 0.9855\n",
      "Epoch 123/150\n",
      "59722/59722 [==============================] - 1s 16us/step - loss: 0.0347 - accuracy: 0.9894 - val_loss: 0.0587 - val_accuracy: 0.9858\n",
      "Epoch 124/150\n",
      "59722/59722 [==============================] - 1s 17us/step - loss: 0.0346 - accuracy: 0.9893 - val_loss: 0.0581 - val_accuracy: 0.9854\n",
      "Epoch 125/150\n",
      "59722/59722 [==============================] - 1s 16us/step - loss: 0.0348 - accuracy: 0.9892 - val_loss: 0.0584 - val_accuracy: 0.9861\n",
      "Epoch 126/150\n",
      "59722/59722 [==============================] - 1s 17us/step - loss: 0.0349 - accuracy: 0.9895 - val_loss: 0.0629 - val_accuracy: 0.9818\n",
      "Epoch 127/150\n",
      "59722/59722 [==============================] - 1s 21us/step - loss: 0.0348 - accuracy: 0.9892 - val_loss: 0.0588 - val_accuracy: 0.9852\n",
      "Epoch 128/150\n",
      "59722/59722 [==============================] - 1s 15us/step - loss: 0.0346 - accuracy: 0.9897 - val_loss: 0.0604 - val_accuracy: 0.9849\n",
      "Epoch 129/150\n",
      "59722/59722 [==============================] - 1s 17us/step - loss: 0.0348 - accuracy: 0.9893 - val_loss: 0.0605 - val_accuracy: 0.9846\n",
      "Epoch 130/150\n",
      "59722/59722 [==============================] - 1s 16us/step - loss: 0.0345 - accuracy: 0.9894 - val_loss: 0.0630 - val_accuracy: 0.9836\n",
      "Epoch 131/150\n",
      "59722/59722 [==============================] - 1s 17us/step - loss: 0.0346 - accuracy: 0.9892 - val_loss: 0.0588 - val_accuracy: 0.9855\n",
      "Epoch 132/150\n",
      "59722/59722 [==============================] - 1s 17us/step - loss: 0.0344 - accuracy: 0.9892 - val_loss: 0.0596 - val_accuracy: 0.9851\n",
      "Epoch 133/150\n",
      "59722/59722 [==============================] - 1s 16us/step - loss: 0.0343 - accuracy: 0.9894 - val_loss: 0.0598 - val_accuracy: 0.9845\n",
      "Epoch 134/150\n",
      "59722/59722 [==============================] - 1s 16us/step - loss: 0.0345 - accuracy: 0.9893 - val_loss: 0.0610 - val_accuracy: 0.9851\n",
      "Epoch 135/150\n",
      "59722/59722 [==============================] - 1s 15us/step - loss: 0.0344 - accuracy: 0.9892 - val_loss: 0.0617 - val_accuracy: 0.9855\n",
      "Epoch 136/150\n",
      "59722/59722 [==============================] - 1s 16us/step - loss: 0.0347 - accuracy: 0.9894 - val_loss: 0.0588 - val_accuracy: 0.9855\n",
      "Epoch 137/150\n",
      "59722/59722 [==============================] - 1s 18us/step - loss: 0.0342 - accuracy: 0.9895 - val_loss: 0.0586 - val_accuracy: 0.9866\n",
      "Epoch 138/150\n",
      "59722/59722 [==============================] - 1s 15us/step - loss: 0.0345 - accuracy: 0.9895 - val_loss: 0.0601 - val_accuracy: 0.9831\n",
      "Epoch 139/150\n",
      "59722/59722 [==============================] - 1s 15us/step - loss: 0.0343 - accuracy: 0.9896 - val_loss: 0.0626 - val_accuracy: 0.9834\n",
      "Epoch 140/150\n",
      "59722/59722 [==============================] - 1s 15us/step - loss: 0.0342 - accuracy: 0.9898 - val_loss: 0.0592 - val_accuracy: 0.9852\n",
      "Epoch 141/150\n",
      "59722/59722 [==============================] - 1s 15us/step - loss: 0.0348 - accuracy: 0.9891 - val_loss: 0.0606 - val_accuracy: 0.9848\n",
      "Epoch 142/150\n",
      "59722/59722 [==============================] - 1s 18us/step - loss: 0.0343 - accuracy: 0.9893 - val_loss: 0.0607 - val_accuracy: 0.9840\n",
      "Epoch 143/150\n",
      "59722/59722 [==============================] - 1s 18us/step - loss: 0.0343 - accuracy: 0.9895 - val_loss: 0.0620 - val_accuracy: 0.9848\n",
      "Epoch 144/150\n",
      "59722/59722 [==============================] - 1s 18us/step - loss: 0.0342 - accuracy: 0.9895 - val_loss: 0.0596 - val_accuracy: 0.9857\n",
      "Epoch 145/150\n",
      "59722/59722 [==============================] - 1s 19us/step - loss: 0.0341 - accuracy: 0.9897 - val_loss: 0.0589 - val_accuracy: 0.9845\n",
      "Epoch 146/150\n",
      "59722/59722 [==============================] - 1s 16us/step - loss: 0.0340 - accuracy: 0.9894 - val_loss: 0.0695 - val_accuracy: 0.9803\n",
      "Epoch 147/150\n",
      "59722/59722 [==============================] - 1s 16us/step - loss: 0.0345 - accuracy: 0.9894 - val_loss: 0.0611 - val_accuracy: 0.9842\n",
      "Epoch 148/150\n",
      "59722/59722 [==============================] - 1s 20us/step - loss: 0.0341 - accuracy: 0.9896 - val_loss: 0.0622 - val_accuracy: 0.9833\n",
      "Epoch 149/150\n",
      "59722/59722 [==============================] - 1s 16us/step - loss: 0.0344 - accuracy: 0.9895 - val_loss: 0.0627 - val_accuracy: 0.9825\n",
      "Epoch 150/150\n",
      "59722/59722 [==============================] - 1s 15us/step - loss: 0.0341 - accuracy: 0.9893 - val_loss: 0.0622 - val_accuracy: 0.9833\n"
     ]
    }
   ],
   "source": [
    "history_class = classifier.fit(x=input_data, y=labels, epochs=150, validation_split=0.10, batch_size=75,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history_class.history['accuracy'])\n",
    "plt.plot(history_class.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.savefig(\"./img/acc_history.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save('./models/my_models/classifier_model04.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_class(predicted_probabilities, threshold=0.2):\n",
    "    classes = []\n",
    "    for i in range(len(predicted_probabilities)):\n",
    "        if(predicted_probabilities[i] >= threshold):\n",
    "            classes.append(1)\n",
    "        else:\n",
    "            classes.append(0)\n",
    "    return np.asarray(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-28fdd1515c3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "predict_prob = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = assign_class(predict_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :99.2199894235854\n",
      "f1Score: 0.9921134147105986\n",
      "recall: 0.8316831683168316\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy :\"+str(accuracy_score(y_test,classes)*100))\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"f1Score: \"+str(f1_score(y_test,classes,average='weighted')))\n",
    "from sklearn.metrics import recall_score\n",
    "print(\"recall: \"+str(recall_score(y_test,classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7337,   25],\n",
       "       [  34,  168]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with only common features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"my_code/norm_dataset/dataset_complete_2\")\n",
    "input_data = dataset.drop(labels=['label'], axis=1)\n",
    "labels = dataset.loc[:,'label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = input_data.drop(\"Unnamed: 0\",axis=1)\n",
    "input_dim = input_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/reboot/anaconda3/envs/Anomaly_Detection_HPC/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_1 (Dense)            (None, 100)               12500     \n",
      "_________________________________________________________________\n",
      "encoder_2 (Dense)            (None, 80)                8080      \n",
      "_________________________________________________________________\n",
      "encoder_3 (Dense)            (None, 60)                4860      \n",
      "_________________________________________________________________\n",
      "encoder_4 (Dense)            (None, 40)                2440      \n",
      "_________________________________________________________________\n",
      "code (Dense)                 (None, 20)                820       \n",
      "_________________________________________________________________\n",
      "decoder_1 (Dense)            (None, 40)                840       \n",
      "_________________________________________________________________\n",
      "decoder_2 (Dense)            (None, 60)                2460      \n",
      "_________________________________________________________________\n",
      "decoder_3 (Dense)            (None, 80)                4880      \n",
      "_________________________________________________________________\n",
      "decoder_4 (Dense)            (None, 100)               8100      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 124)               12524     \n",
      "=================================================================\n",
      "Total params: 57,504\n",
      "Trainable params: 57,504\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "autoencoder = Sequential()\n",
    "autoencoder.add(Dense(100, activation='relu', input_dim=input_dim, name='encoder_1'))\n",
    "autoencoder.add(Dense(80, activation='relu', name=\"encoder_2\"))\n",
    "autoencoder.add(Dense(60, activation='relu', name=\"encoder_3\"))\n",
    "autoencoder.add(Dense(40, activation='relu', name=\"encoder_4\"))\n",
    "autoencoder.add(Dense(20, activation='relu', name='code'))\n",
    "autoencoder.add(Dense(40, activation='relu', name=\"decoder_1\"))\n",
    "autoencoder.add(Dense(60, activation='relu', name=\"decoder_2\"))\n",
    "autoencoder.add(Dense(80, activation='relu', name=\"decoder_3\"))\n",
    "autoencoder.add(Dense(100, activation='relu', name=\"decoder_4\"))\n",
    "autoencoder.add(Dense(input_dim, activation='sigmoid', name='output'))\n",
    "autoencoder.compile(optimizer='adam', loss=\"mean_squared_error\")\n",
    "print(autoencoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/reboot/anaconda3/envs/Anomaly_Detection_HPC/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 21174 samples, validate on 5294 samples\n",
      "Epoch 1/150\n",
      "21174/21174 [==============================] - 2s 86us/step - loss: 0.0278 - val_loss: 0.0222\n",
      "Epoch 2/150\n",
      "21174/21174 [==============================] - 1s 32us/step - loss: 0.0082 - val_loss: 0.0209\n",
      "Epoch 3/150\n",
      "21174/21174 [==============================] - 1s 34us/step - loss: 0.0056 - val_loss: 0.0202\n",
      "Epoch 4/150\n",
      "21174/21174 [==============================] - 1s 35us/step - loss: 0.0043 - val_loss: 0.0200\n",
      "Epoch 5/150\n",
      "21174/21174 [==============================] - 1s 32us/step - loss: 0.0035 - val_loss: 0.0201\n",
      "Epoch 6/150\n",
      "21174/21174 [==============================] - 1s 35us/step - loss: 0.0030 - val_loss: 0.0207\n",
      "Epoch 7/150\n",
      "21174/21174 [==============================] - 1s 37us/step - loss: 0.0027 - val_loss: 0.0205\n",
      "Epoch 8/150\n",
      "21174/21174 [==============================] - 1s 40us/step - loss: 0.0025 - val_loss: 0.0186\n",
      "Epoch 9/150\n",
      "21174/21174 [==============================] - 1s 34us/step - loss: 0.0024 - val_loss: 0.0184\n",
      "Epoch 10/150\n",
      "21174/21174 [==============================] - 1s 36us/step - loss: 0.0023 - val_loss: 0.0181\n",
      "Epoch 11/150\n",
      "21174/21174 [==============================] - 1s 34us/step - loss: 0.0022 - val_loss: 0.0188\n",
      "Epoch 12/150\n",
      "21174/21174 [==============================] - 1s 32us/step - loss: 0.0021 - val_loss: 0.0187\n",
      "Epoch 13/150\n",
      "21174/21174 [==============================] - 1s 35us/step - loss: 0.0020 - val_loss: 0.0189\n",
      "Epoch 14/150\n",
      "21174/21174 [==============================] - 1s 37us/step - loss: 0.0019 - val_loss: 0.0182\n",
      "Epoch 15/150\n",
      "21174/21174 [==============================] - 1s 42us/step - loss: 0.0019 - val_loss: 0.0176\n",
      "Epoch 16/150\n",
      "21174/21174 [==============================] - 1s 46us/step - loss: 0.0018 - val_loss: 0.0180\n",
      "Epoch 17/150\n",
      "21174/21174 [==============================] - 1s 44us/step - loss: 0.0018 - val_loss: 0.0186\n",
      "Epoch 18/150\n",
      "21174/21174 [==============================] - 1s 44us/step - loss: 0.0017 - val_loss: 0.0182\n",
      "Epoch 19/150\n",
      "21174/21174 [==============================] - 1s 41us/step - loss: 0.0017 - val_loss: 0.0182\n",
      "Epoch 20/150\n",
      "21174/21174 [==============================] - 1s 41us/step - loss: 0.0016 - val_loss: 0.0180\n",
      "Epoch 21/150\n",
      "21174/21174 [==============================] - 1s 36us/step - loss: 0.0016 - val_loss: 0.0182\n",
      "Epoch 22/150\n",
      "21174/21174 [==============================] - 1s 31us/step - loss: 0.0015 - val_loss: 0.0176\n",
      "Epoch 23/150\n",
      "21174/21174 [==============================] - 1s 36us/step - loss: 0.0015 - val_loss: 0.0181\n",
      "Epoch 24/150\n",
      "21174/21174 [==============================] - 1s 35us/step - loss: 0.0015 - val_loss: 0.0180\n",
      "Epoch 25/150\n",
      "21174/21174 [==============================] - 1s 34us/step - loss: 0.0014 - val_loss: 0.0178\n",
      "Epoch 26/150\n",
      "21174/21174 [==============================] - 1s 32us/step - loss: 0.0014 - val_loss: 0.0167\n",
      "Epoch 27/150\n",
      "21174/21174 [==============================] - 1s 42us/step - loss: 0.0014 - val_loss: 0.0176\n",
      "Epoch 28/150\n",
      "21174/21174 [==============================] - 1s 41us/step - loss: 0.0013 - val_loss: 0.0169\n",
      "Epoch 29/150\n",
      "21174/21174 [==============================] - 1s 35us/step - loss: 0.0013 - val_loss: 0.0164\n",
      "Epoch 30/150\n",
      "21174/21174 [==============================] - 1s 33us/step - loss: 0.0013 - val_loss: 0.0165\n",
      "Epoch 31/150\n",
      "21174/21174 [==============================] - 1s 31us/step - loss: 0.0013 - val_loss: 0.0164\n",
      "Epoch 32/150\n",
      "21174/21174 [==============================] - 1s 31us/step - loss: 0.0012 - val_loss: 0.0158\n",
      "Epoch 33/150\n",
      "21174/21174 [==============================] - 1s 31us/step - loss: 0.0012 - val_loss: 0.0154\n",
      "Epoch 34/150\n",
      "21174/21174 [==============================] - 1s 32us/step - loss: 0.0012 - val_loss: 0.0160\n",
      "Epoch 35/150\n",
      "21174/21174 [==============================] - 1s 32us/step - loss: 0.0012 - val_loss: 0.0157\n",
      "Epoch 36/150\n",
      "21174/21174 [==============================] - 1s 30us/step - loss: 0.0011 - val_loss: 0.0156\n",
      "Epoch 37/150\n",
      "21174/21174 [==============================] - 1s 32us/step - loss: 0.0011 - val_loss: 0.0163\n",
      "Epoch 38/150\n",
      "21174/21174 [==============================] - 1s 36us/step - loss: 0.0011 - val_loss: 0.0159\n",
      "Epoch 39/150\n",
      "21174/21174 [==============================] - 1s 31us/step - loss: 0.0011 - val_loss: 0.0159\n",
      "Epoch 40/150\n",
      "21174/21174 [==============================] - 1s 35us/step - loss: 0.0011 - val_loss: 0.0161\n",
      "Epoch 41/150\n",
      "21174/21174 [==============================] - 1s 34us/step - loss: 0.0011 - val_loss: 0.0162\n",
      "Epoch 42/150\n",
      "21174/21174 [==============================] - 1s 36us/step - loss: 0.0010 - val_loss: 0.0156\n",
      "Epoch 43/150\n",
      "21174/21174 [==============================] - 1s 35us/step - loss: 0.0010 - val_loss: 0.0161\n",
      "Epoch 44/150\n",
      "21174/21174 [==============================] - 1s 35us/step - loss: 0.0010 - val_loss: 0.0163\n",
      "Epoch 45/150\n",
      "21174/21174 [==============================] - 1s 40us/step - loss: 9.9742e-04 - val_loss: 0.0162\n",
      "Epoch 46/150\n",
      "21174/21174 [==============================] - 1s 44us/step - loss: 9.8775e-04 - val_loss: 0.0157\n",
      "Epoch 47/150\n",
      "21174/21174 [==============================] - 1s 45us/step - loss: 9.6688e-04 - val_loss: 0.0160\n",
      "Epoch 48/150\n",
      "21174/21174 [==============================] - 1s 38us/step - loss: 9.5774e-04 - val_loss: 0.0157\n",
      "Epoch 49/150\n",
      "21174/21174 [==============================] - 1s 37us/step - loss: 9.5239e-04 - val_loss: 0.0159\n",
      "Epoch 50/150\n",
      "21174/21174 [==============================] - 1s 35us/step - loss: 9.4466e-04 - val_loss: 0.0158\n",
      "Epoch 51/150\n",
      "21174/21174 [==============================] - 1s 34us/step - loss: 9.2843e-04 - val_loss: 0.0157\n",
      "Epoch 52/150\n",
      "21174/21174 [==============================] - 1s 36us/step - loss: 9.1166e-04 - val_loss: 0.0159\n",
      "Epoch 53/150\n",
      "21174/21174 [==============================] - 1s 34us/step - loss: 9.1532e-04 - val_loss: 0.0163\n",
      "Epoch 54/150\n",
      "21174/21174 [==============================] - 1s 32us/step - loss: 8.9350e-04 - val_loss: 0.0153\n",
      "Epoch 55/150\n",
      "21174/21174 [==============================] - 1s 34us/step - loss: 8.9404e-04 - val_loss: 0.0157\n",
      "Epoch 56/150\n",
      "21174/21174 [==============================] - 1s 33us/step - loss: 8.7624e-04 - val_loss: 0.0154\n",
      "Epoch 57/150\n",
      "21174/21174 [==============================] - 1s 30us/step - loss: 8.7439e-04 - val_loss: 0.0158\n",
      "Epoch 58/150\n",
      "21174/21174 [==============================] - 1s 30us/step - loss: 8.6820e-04 - val_loss: 0.0162\n",
      "Epoch 59/150\n",
      "21174/21174 [==============================] - 1s 33us/step - loss: 8.5366e-04 - val_loss: 0.0159\n",
      "Epoch 60/150\n",
      "21174/21174 [==============================] - 1s 32us/step - loss: 8.5421e-04 - val_loss: 0.0159\n",
      "Epoch 61/150\n",
      "21174/21174 [==============================] - 1s 30us/step - loss: 8.4731e-04 - val_loss: 0.0153\n",
      "Epoch 62/150\n",
      "21174/21174 [==============================] - 1s 30us/step - loss: 8.4632e-04 - val_loss: 0.0158\n",
      "Epoch 63/150\n",
      "21174/21174 [==============================] - 1s 29us/step - loss: 8.3579e-04 - val_loss: 0.0156\n",
      "Epoch 64/150\n",
      "21174/21174 [==============================] - 1s 30us/step - loss: 8.2562e-04 - val_loss: 0.0160\n",
      "Epoch 65/150\n",
      "21174/21174 [==============================] - 1s 30us/step - loss: 8.2151e-04 - val_loss: 0.0152\n",
      "Epoch 66/150\n",
      "21174/21174 [==============================] - 1s 30us/step - loss: 8.0046e-04 - val_loss: 0.0158\n",
      "Epoch 67/150\n",
      "21174/21174 [==============================] - 1s 34us/step - loss: 7.9714e-04 - val_loss: 0.0155\n",
      "Epoch 68/150\n",
      "21174/21174 [==============================] - 1s 35us/step - loss: 7.9040e-04 - val_loss: 0.0153\n",
      "Epoch 69/150\n",
      "21174/21174 [==============================] - 1s 34us/step - loss: 7.8674e-04 - val_loss: 0.0155\n",
      "Epoch 70/150\n",
      "21174/21174 [==============================] - 1s 35us/step - loss: 7.7433e-04 - val_loss: 0.0156\n",
      "Epoch 71/150\n",
      "21174/21174 [==============================] - 1s 35us/step - loss: 7.7077e-04 - val_loss: 0.0160\n",
      "Epoch 72/150\n",
      "21174/21174 [==============================] - 1s 36us/step - loss: 7.6995e-04 - val_loss: 0.0158\n",
      "Epoch 73/150\n",
      "21174/21174 [==============================] - 1s 36us/step - loss: 7.6754e-04 - val_loss: 0.0155\n",
      "Epoch 74/150\n",
      "21174/21174 [==============================] - 1s 36us/step - loss: 7.5697e-04 - val_loss: 0.0152\n",
      "Epoch 75/150\n",
      "21174/21174 [==============================] - 1s 35us/step - loss: 7.5949e-04 - val_loss: 0.0154\n",
      "Epoch 76/150\n",
      "21174/21174 [==============================] - 1s 36us/step - loss: 7.5163e-04 - val_loss: 0.0157\n",
      "Epoch 77/150\n",
      "21174/21174 [==============================] - 1s 36us/step - loss: 7.4387e-04 - val_loss: 0.0157\n",
      "Epoch 78/150\n",
      "21174/21174 [==============================] - 1s 36us/step - loss: 7.4302e-04 - val_loss: 0.0154\n",
      "Epoch 79/150\n",
      "21174/21174 [==============================] - 1s 36us/step - loss: 7.4490e-04 - val_loss: 0.0155\n",
      "Epoch 80/150\n",
      "21174/21174 [==============================] - 1s 34us/step - loss: 7.4295e-04 - val_loss: 0.0152\n",
      "Epoch 81/150\n",
      "21174/21174 [==============================] - 1s 37us/step - loss: 7.3684e-04 - val_loss: 0.0156\n",
      "Epoch 82/150\n",
      "21174/21174 [==============================] - 1s 38us/step - loss: 7.2697e-04 - val_loss: 0.0155\n",
      "Epoch 83/150\n",
      "21174/21174 [==============================] - 1s 35us/step - loss: 7.2981e-04 - val_loss: 0.0158\n",
      "Epoch 84/150\n",
      "21174/21174 [==============================] - 1s 33us/step - loss: 7.2271e-04 - val_loss: 0.0157\n",
      "Epoch 85/150\n",
      "21174/21174 [==============================] - 1s 33us/step - loss: 7.2558e-04 - val_loss: 0.0161\n",
      "Epoch 86/150\n",
      "21174/21174 [==============================] - 1s 32us/step - loss: 7.1724e-04 - val_loss: 0.0151\n",
      "Epoch 87/150\n",
      "21174/21174 [==============================] - 1s 33us/step - loss: 7.1585e-04 - val_loss: 0.0154\n",
      "Epoch 88/150\n",
      "21174/21174 [==============================] - 1s 33us/step - loss: 7.1699e-04 - val_loss: 0.0153\n",
      "Epoch 89/150\n",
      "21174/21174 [==============================] - 1s 33us/step - loss: 7.2164e-04 - val_loss: 0.0154\n",
      "Epoch 90/150\n",
      "21174/21174 [==============================] - 1s 36us/step - loss: 7.1307e-04 - val_loss: 0.0153\n",
      "Epoch 91/150\n",
      "21174/21174 [==============================] - 1s 36us/step - loss: 6.9675e-04 - val_loss: 0.0153\n",
      "Epoch 92/150\n",
      "21174/21174 [==============================] - 1s 35us/step - loss: 7.0132e-04 - val_loss: 0.0153\n",
      "Epoch 93/150\n",
      "21174/21174 [==============================] - 1s 33us/step - loss: 7.0114e-04 - val_loss: 0.0153\n",
      "Epoch 94/150\n",
      "21174/21174 [==============================] - 1s 34us/step - loss: 7.1564e-04 - val_loss: 0.0151\n",
      "Epoch 95/150\n",
      "21174/21174 [==============================] - 1s 36us/step - loss: 6.8766e-04 - val_loss: 0.0153\n",
      "Epoch 96/150\n",
      "21174/21174 [==============================] - 1s 36us/step - loss: 6.8556e-04 - val_loss: 0.0154\n",
      "Epoch 97/150\n",
      "21174/21174 [==============================] - 1s 33us/step - loss: 6.8689e-04 - val_loss: 0.0157\n",
      "Epoch 98/150\n",
      "21174/21174 [==============================] - 1s 34us/step - loss: 6.8393e-04 - val_loss: 0.0151\n",
      "Epoch 99/150\n",
      "21174/21174 [==============================] - 1s 34us/step - loss: 6.8047e-04 - val_loss: 0.0153\n",
      "Epoch 100/150\n",
      "21174/21174 [==============================] - 1s 33us/step - loss: 6.8473e-04 - val_loss: 0.0151\n",
      "Epoch 101/150\n",
      "21174/21174 [==============================] - 1s 34us/step - loss: 6.8305e-04 - val_loss: 0.0159\n",
      "Epoch 102/150\n",
      "21174/21174 [==============================] - 1s 35us/step - loss: 6.7972e-04 - val_loss: 0.0153\n",
      "Epoch 103/150\n",
      "21174/21174 [==============================] - 1s 40us/step - loss: 6.8044e-04 - val_loss: 0.0155\n",
      "Epoch 104/150\n",
      "21174/21174 [==============================] - 1s 36us/step - loss: 6.7209e-04 - val_loss: 0.0152\n",
      "Epoch 105/150\n",
      "21174/21174 [==============================] - 1s 34us/step - loss: 6.6969e-04 - val_loss: 0.0152\n",
      "Epoch 106/150\n",
      "21174/21174 [==============================] - 1s 34us/step - loss: 6.6597e-04 - val_loss: 0.0153\n",
      "Epoch 107/150\n",
      "21174/21174 [==============================] - 1s 34us/step - loss: 6.6305e-04 - val_loss: 0.0150\n",
      "Epoch 108/150\n",
      "21174/21174 [==============================] - 1s 35us/step - loss: 6.6933e-04 - val_loss: 0.0151\n",
      "Epoch 109/150\n",
      "21174/21174 [==============================] - 1s 38us/step - loss: 6.5508e-04 - val_loss: 0.0151\n",
      "Epoch 110/150\n",
      "21174/21174 [==============================] - 1s 35us/step - loss: 6.6091e-04 - val_loss: 0.0153\n",
      "Epoch 111/150\n",
      "21174/21174 [==============================] - 1s 42us/step - loss: 6.5512e-04 - val_loss: 0.0156\n",
      "Epoch 112/150\n",
      "21174/21174 [==============================] - 1s 37us/step - loss: 6.5631e-04 - val_loss: 0.0156\n",
      "Epoch 113/150\n",
      "21174/21174 [==============================] - 1s 36us/step - loss: 6.5473e-04 - val_loss: 0.0154\n",
      "Epoch 114/150\n",
      "21174/21174 [==============================] - 1s 35us/step - loss: 6.5648e-04 - val_loss: 0.0154\n",
      "Epoch 115/150\n",
      "21174/21174 [==============================] - 1s 37us/step - loss: 6.4162e-04 - val_loss: 0.0154\n",
      "Epoch 116/150\n",
      "21174/21174 [==============================] - 1s 47us/step - loss: 6.4433e-04 - val_loss: 0.0150\n",
      "Epoch 117/150\n",
      "21174/21174 [==============================] - 1s 38us/step - loss: 6.5014e-04 - val_loss: 0.0158\n",
      "Epoch 118/150\n",
      "21174/21174 [==============================] - 1s 38us/step - loss: 6.4043e-04 - val_loss: 0.0154\n",
      "Epoch 119/150\n",
      "21174/21174 [==============================] - 1s 37us/step - loss: 6.4059e-04 - val_loss: 0.0149\n",
      "Epoch 120/150\n",
      "21174/21174 [==============================] - 1s 33us/step - loss: 6.3777e-04 - val_loss: 0.0155\n",
      "Epoch 121/150\n",
      "21174/21174 [==============================] - 1s 35us/step - loss: 6.3784e-04 - val_loss: 0.0154\n",
      "Epoch 122/150\n",
      "21174/21174 [==============================] - 1s 34us/step - loss: 6.3525e-04 - val_loss: 0.0158\n",
      "Epoch 123/150\n",
      "21174/21174 [==============================] - 1s 36us/step - loss: 6.3459e-04 - val_loss: 0.0153\n",
      "Epoch 124/150\n",
      "21174/21174 [==============================] - 1s 39us/step - loss: 6.2929e-04 - val_loss: 0.0151\n",
      "Epoch 125/150\n",
      "21174/21174 [==============================] - 1s 35us/step - loss: 6.2643e-04 - val_loss: 0.0152\n",
      "Epoch 126/150\n",
      "21174/21174 [==============================] - 1s 35us/step - loss: 6.2114e-04 - val_loss: 0.0158\n",
      "Epoch 127/150\n",
      "21174/21174 [==============================] - 1s 35us/step - loss: 6.3083e-04 - val_loss: 0.0152\n",
      "Epoch 128/150\n",
      "21174/21174 [==============================] - 1s 34us/step - loss: 6.3000e-04 - val_loss: 0.0158\n",
      "Epoch 129/150\n",
      "21174/21174 [==============================] - 1s 35us/step - loss: 6.2013e-04 - val_loss: 0.0157\n",
      "Epoch 130/150\n",
      "21174/21174 [==============================] - 1s 35us/step - loss: 6.1778e-04 - val_loss: 0.0151\n",
      "Epoch 131/150\n",
      "21174/21174 [==============================] - 1s 34us/step - loss: 6.1843e-04 - val_loss: 0.0152\n",
      "Epoch 132/150\n",
      "21174/21174 [==============================] - 1s 33us/step - loss: 6.1082e-04 - val_loss: 0.0155\n",
      "Epoch 133/150\n",
      "21174/21174 [==============================] - 1s 33us/step - loss: 6.1907e-04 - val_loss: 0.0157\n",
      "Epoch 134/150\n",
      "21174/21174 [==============================] - 1s 34us/step - loss: 6.0727e-04 - val_loss: 0.0154\n",
      "Epoch 135/150\n",
      "21174/21174 [==============================] - 1s 33us/step - loss: 6.0690e-04 - val_loss: 0.0159\n",
      "Epoch 136/150\n",
      "21174/21174 [==============================] - 1s 33us/step - loss: 6.0791e-04 - val_loss: 0.0157\n",
      "Epoch 137/150\n",
      "21174/21174 [==============================] - 1s 35us/step - loss: 6.0676e-04 - val_loss: 0.0157\n",
      "Epoch 138/150\n",
      "21174/21174 [==============================] - 1s 35us/step - loss: 6.2908e-04 - val_loss: 0.0158\n",
      "Epoch 139/150\n",
      "21174/21174 [==============================] - 1s 33us/step - loss: 6.0141e-04 - val_loss: 0.0157\n",
      "Epoch 140/150\n",
      "21174/21174 [==============================] - 1s 35us/step - loss: 6.6162e-04 - val_loss: 0.0156\n",
      "Epoch 141/150\n",
      "21174/21174 [==============================] - 1s 34us/step - loss: 6.0843e-04 - val_loss: 0.0161\n",
      "Epoch 142/150\n",
      "21174/21174 [==============================] - 1s 33us/step - loss: 5.9427e-04 - val_loss: 0.0156\n",
      "Epoch 143/150\n",
      "21174/21174 [==============================] - 1s 35us/step - loss: 5.9124e-04 - val_loss: 0.0156\n",
      "Epoch 144/150\n",
      "21174/21174 [==============================] - 1s 36us/step - loss: 5.9506e-04 - val_loss: 0.0161\n",
      "Epoch 145/150\n",
      "21174/21174 [==============================] - 1s 38us/step - loss: 5.8869e-04 - val_loss: 0.0159\n",
      "Epoch 146/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21174/21174 [==============================] - 1s 40us/step - loss: 5.9110e-04 - val_loss: 0.0159\n",
      "Epoch 147/150\n",
      "21174/21174 [==============================] - 1s 36us/step - loss: 5.8738e-04 - val_loss: 0.0160\n",
      "Epoch 148/150\n",
      "21174/21174 [==============================] - 1s 34us/step - loss: 5.8742e-04 - val_loss: 0.0160\n",
      "Epoch 149/150\n",
      "21174/21174 [==============================] - 1s 36us/step - loss: 5.9835e-04 - val_loss: 0.0158\n",
      "Epoch 150/150\n",
      "21174/21174 [==============================] - 1s 36us/step - loss: 5.9711e-04 - val_loss: 0.0156\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(x=input_data, y=input_data, epochs=150, validation_split=0.20, batch_size=75,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26468/26468 [==============================] - 1s 21us/step\n",
      "0.0036140324523115386\n"
     ]
    }
   ],
   "source": [
    "loss = autoencoder.evaluate(input_data, input_data)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder (Model)              (None, 20)                28700     \n",
      "_________________________________________________________________\n",
      "hidden (Dense)               (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "hidden3 (Dense)              (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 29,391\n",
      "Trainable params: 691\n",
      "Non-trainable params: 28,700\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#classifier model\n",
    "encoder = Model(inputs=autoencoder.get_layer(\"encoder_1\").input, outputs=autoencoder.get_layer(\"code\").output)\n",
    "classifier = Sequential()\n",
    "classifier.add(encoder)\n",
    "classifier.add(Dense(20, activation='relu', name=\"hidden\"))\n",
    "classifier.add(Dense(10, activation='relu', name=\"hidden2\"))\n",
    "classifier.add(Dense(5, activation='relu', name=\"hidden3\"))\n",
    "classifier.add(Dense(1,activation=\"sigmoid\", name=\"output\"))\n",
    "classifier.layers[0].name=\"encoder\"\n",
    "classifier.layers[0].trainable=False\n",
    "classifier.compile(optimizer='adam', loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "print(classifier.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 68262 samples, validate on 7585 samples\n",
      "Epoch 1/150\n",
      "68262/68262 [==============================] - 1s 16us/step - loss: 0.0242 - accuracy: 0.9916 - val_loss: 0.0858 - val_accuracy: 0.9735\n",
      "Epoch 2/150\n",
      "68262/68262 [==============================] - 1s 21us/step - loss: 0.0241 - accuracy: 0.9918 - val_loss: 0.0812 - val_accuracy: 0.9788\n",
      "Epoch 3/150\n",
      "68262/68262 [==============================] - 1s 21us/step - loss: 0.0242 - accuracy: 0.9919 - val_loss: 0.0964 - val_accuracy: 0.9699\n",
      "Epoch 4/150\n",
      "68262/68262 [==============================] - 2s 22us/step - loss: 0.0245 - accuracy: 0.9916 - val_loss: 0.0818 - val_accuracy: 0.9800\n",
      "Epoch 5/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0243 - accuracy: 0.9917 - val_loss: 0.0832 - val_accuracy: 0.9784\n",
      "Epoch 6/150\n",
      "68262/68262 [==============================] - 1s 17us/step - loss: 0.0239 - accuracy: 0.9921 - val_loss: 0.0928 - val_accuracy: 0.9702\n",
      "Epoch 7/150\n",
      "68262/68262 [==============================] - 1s 21us/step - loss: 0.0242 - accuracy: 0.9919 - val_loss: 0.0897 - val_accuracy: 0.9719\n",
      "Epoch 8/150\n",
      "68262/68262 [==============================] - 1s 22us/step - loss: 0.0242 - accuracy: 0.9920 - val_loss: 0.0833 - val_accuracy: 0.9792\n",
      "Epoch 9/150\n",
      "68262/68262 [==============================] - 1s 21us/step - loss: 0.0238 - accuracy: 0.9919 - val_loss: 0.0850 - val_accuracy: 0.9792\n",
      "Epoch 10/150\n",
      "68262/68262 [==============================] - 1s 20us/step - loss: 0.0240 - accuracy: 0.9920 - val_loss: 0.0841 - val_accuracy: 0.9802\n",
      "Epoch 11/150\n",
      "68262/68262 [==============================] - 1s 20us/step - loss: 0.0237 - accuracy: 0.9918 - val_loss: 0.0918 - val_accuracy: 0.9709\n",
      "Epoch 12/150\n",
      "68262/68262 [==============================] - 1s 22us/step - loss: 0.0240 - accuracy: 0.9920 - val_loss: 0.0877 - val_accuracy: 0.9773\n",
      "Epoch 13/150\n",
      "68262/68262 [==============================] - 1s 21us/step - loss: 0.0240 - accuracy: 0.9920 - val_loss: 0.0809 - val_accuracy: 0.9793\n",
      "Epoch 14/150\n",
      "68262/68262 [==============================] - 1s 19us/step - loss: 0.0239 - accuracy: 0.9920 - val_loss: 0.0870 - val_accuracy: 0.9728\n",
      "Epoch 15/150\n",
      "68262/68262 [==============================] - 1s 22us/step - loss: 0.0241 - accuracy: 0.9917 - val_loss: 0.0896 - val_accuracy: 0.9717\n",
      "Epoch 16/150\n",
      "68262/68262 [==============================] - 1s 17us/step - loss: 0.0240 - accuracy: 0.9920 - val_loss: 0.0809 - val_accuracy: 0.9846\n",
      "Epoch 17/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0238 - accuracy: 0.9919 - val_loss: 0.0815 - val_accuracy: 0.9860\n",
      "Epoch 18/150\n",
      "68262/68262 [==============================] - 1s 17us/step - loss: 0.0235 - accuracy: 0.9919 - val_loss: 0.0862 - val_accuracy: 0.9780\n",
      "Epoch 19/150\n",
      "68262/68262 [==============================] - 1s 20us/step - loss: 0.0238 - accuracy: 0.9920 - val_loss: 0.0893 - val_accuracy: 0.9724\n",
      "Epoch 20/150\n",
      "68262/68262 [==============================] - 1s 17us/step - loss: 0.0238 - accuracy: 0.9920 - val_loss: 0.0882 - val_accuracy: 0.9730\n",
      "Epoch 21/150\n",
      "68262/68262 [==============================] - 1s 17us/step - loss: 0.0237 - accuracy: 0.9920 - val_loss: 0.0914 - val_accuracy: 0.9724\n",
      "Epoch 22/150\n",
      "68262/68262 [==============================] - 1s 17us/step - loss: 0.0236 - accuracy: 0.9919 - val_loss: 0.0852 - val_accuracy: 0.9781\n",
      "Epoch 23/150\n",
      "68262/68262 [==============================] - 1s 20us/step - loss: 0.0233 - accuracy: 0.9924 - val_loss: 0.0830 - val_accuracy: 0.9862\n",
      "Epoch 24/150\n",
      "68262/68262 [==============================] - 1s 19us/step - loss: 0.0236 - accuracy: 0.9920 - val_loss: 0.0856 - val_accuracy: 0.9738\n",
      "Epoch 25/150\n",
      "68262/68262 [==============================] - 2s 25us/step - loss: 0.0234 - accuracy: 0.9921 - val_loss: 0.0876 - val_accuracy: 0.9789\n",
      "Epoch 26/150\n",
      "68262/68262 [==============================] - 2s 27us/step - loss: 0.0236 - accuracy: 0.9920 - val_loss: 0.0831 - val_accuracy: 0.9784\n",
      "Epoch 27/150\n",
      "68262/68262 [==============================] - 2s 24us/step - loss: 0.0232 - accuracy: 0.9923 - val_loss: 0.0831 - val_accuracy: 0.9767\n",
      "Epoch 28/150\n",
      "68262/68262 [==============================] - 2s 25us/step - loss: 0.0240 - accuracy: 0.9921 - val_loss: 0.0853 - val_accuracy: 0.9792\n",
      "Epoch 29/150\n",
      "68262/68262 [==============================] - 2s 25us/step - loss: 0.0232 - accuracy: 0.9922 - val_loss: 0.0846 - val_accuracy: 0.9790\n",
      "Epoch 30/150\n",
      "68262/68262 [==============================] - 2s 25us/step - loss: 0.0233 - accuracy: 0.9921 - val_loss: 0.0819 - val_accuracy: 0.9801\n",
      "Epoch 31/150\n",
      "68262/68262 [==============================] - 1s 20us/step - loss: 0.0237 - accuracy: 0.9918 - val_loss: 0.0887 - val_accuracy: 0.9764\n",
      "Epoch 32/150\n",
      "68262/68262 [==============================] - 1s 19us/step - loss: 0.0235 - accuracy: 0.9920 - val_loss: 0.0818 - val_accuracy: 0.9837\n",
      "Epoch 33/150\n",
      "68262/68262 [==============================] - 1s 22us/step - loss: 0.0233 - accuracy: 0.9921 - val_loss: 0.0870 - val_accuracy: 0.9735\n",
      "Epoch 34/150\n",
      "68262/68262 [==============================] - 1s 20us/step - loss: 0.0233 - accuracy: 0.9922 - val_loss: 0.0832 - val_accuracy: 0.9790\n",
      "Epoch 35/150\n",
      "68262/68262 [==============================] - 1s 19us/step - loss: 0.0234 - accuracy: 0.9922 - val_loss: 0.0846 - val_accuracy: 0.9801\n",
      "Epoch 36/150\n",
      "68262/68262 [==============================] - 1s 17us/step - loss: 0.0231 - accuracy: 0.9921 - val_loss: 0.0955 - val_accuracy: 0.9705\n",
      "Epoch 37/150\n",
      "68262/68262 [==============================] - 1s 16us/step - loss: 0.0232 - accuracy: 0.9921 - val_loss: 0.0844 - val_accuracy: 0.9790\n",
      "Epoch 38/150\n",
      "68262/68262 [==============================] - 1s 16us/step - loss: 0.0233 - accuracy: 0.9922 - val_loss: 0.0866 - val_accuracy: 0.9781\n",
      "Epoch 39/150\n",
      "68262/68262 [==============================] - 1s 22us/step - loss: 0.0233 - accuracy: 0.9920 - val_loss: 0.0914 - val_accuracy: 0.9706\n",
      "Epoch 40/150\n",
      "68262/68262 [==============================] - 2s 23us/step - loss: 0.0230 - accuracy: 0.9924 - val_loss: 0.0842 - val_accuracy: 0.9806\n",
      "Epoch 41/150\n",
      "68262/68262 [==============================] - 2s 22us/step - loss: 0.0232 - accuracy: 0.9922 - val_loss: 0.0880 - val_accuracy: 0.9731\n",
      "Epoch 42/150\n",
      "68262/68262 [==============================] - 1s 22us/step - loss: 0.0230 - accuracy: 0.9925 - val_loss: 0.0848 - val_accuracy: 0.9742\n",
      "Epoch 43/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0230 - accuracy: 0.9925 - val_loss: 0.0825 - val_accuracy: 0.9859\n",
      "Epoch 44/150\n",
      "68262/68262 [==============================] - 1s 19us/step - loss: 0.0230 - accuracy: 0.9926 - val_loss: 0.0903 - val_accuracy: 0.9727\n",
      "Epoch 45/150\n",
      "68262/68262 [==============================] - 1s 21us/step - loss: 0.0230 - accuracy: 0.9923 - val_loss: 0.0821 - val_accuracy: 0.9823\n",
      "Epoch 46/150\n",
      "68262/68262 [==============================] - 1s 19us/step - loss: 0.0229 - accuracy: 0.9923 - val_loss: 0.0827 - val_accuracy: 0.9785\n",
      "Epoch 47/150\n",
      "68262/68262 [==============================] - 1s 17us/step - loss: 0.0229 - accuracy: 0.9924 - val_loss: 0.0918 - val_accuracy: 0.9719\n",
      "Epoch 48/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0232 - accuracy: 0.9920 - val_loss: 0.0906 - val_accuracy: 0.9761\n",
      "Epoch 49/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0228 - accuracy: 0.9924 - val_loss: 0.0802 - val_accuracy: 0.9801\n",
      "Epoch 50/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0229 - accuracy: 0.9923 - val_loss: 0.0860 - val_accuracy: 0.9738\n",
      "Epoch 51/150\n",
      "68262/68262 [==============================] - 1s 17us/step - loss: 0.0233 - accuracy: 0.9920 - val_loss: 0.0947 - val_accuracy: 0.9701\n",
      "Epoch 52/150\n",
      "68262/68262 [==============================] - 2s 23us/step - loss: 0.0228 - accuracy: 0.9923 - val_loss: 0.0827 - val_accuracy: 0.9776\n",
      "Epoch 53/150\n",
      "68262/68262 [==============================] - 1s 17us/step - loss: 0.0232 - accuracy: 0.9922 - val_loss: 0.0918 - val_accuracy: 0.9734\n",
      "Epoch 54/150\n",
      "68262/68262 [==============================] - 1s 21us/step - loss: 0.0229 - accuracy: 0.9922 - val_loss: 0.0872 - val_accuracy: 0.9739\n",
      "Epoch 55/150\n",
      "68262/68262 [==============================] - 3s 38us/step - loss: 0.0229 - accuracy: 0.9922 - val_loss: 0.0807 - val_accuracy: 0.9862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/150\n",
      "68262/68262 [==============================] - 1s 17us/step - loss: 0.0230 - accuracy: 0.9921 - val_loss: 0.0857 - val_accuracy: 0.9751\n",
      "Epoch 57/150\n",
      "68262/68262 [==============================] - 1s 17us/step - loss: 0.0225 - accuracy: 0.9925 - val_loss: 0.0850 - val_accuracy: 0.9738\n",
      "Epoch 58/150\n",
      "68262/68262 [==============================] - 1s 17us/step - loss: 0.0230 - accuracy: 0.9924 - val_loss: 0.0866 - val_accuracy: 0.9846\n",
      "Epoch 59/150\n",
      "68262/68262 [==============================] - 1s 17us/step - loss: 0.0231 - accuracy: 0.9923 - val_loss: 0.0886 - val_accuracy: 0.9717\n",
      "Epoch 60/150\n",
      "68262/68262 [==============================] - 1s 17us/step - loss: 0.0229 - accuracy: 0.9925 - val_loss: 0.0930 - val_accuracy: 0.9710\n",
      "Epoch 61/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0226 - accuracy: 0.9923 - val_loss: 0.0837 - val_accuracy: 0.9781\n",
      "Epoch 62/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0227 - accuracy: 0.9924 - val_loss: 0.0830 - val_accuracy: 0.9775\n",
      "Epoch 63/150\n",
      "68262/68262 [==============================] - 1s 17us/step - loss: 0.0230 - accuracy: 0.9924 - val_loss: 0.0858 - val_accuracy: 0.9743\n",
      "Epoch 64/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0225 - accuracy: 0.9925 - val_loss: 0.0843 - val_accuracy: 0.9851\n",
      "Epoch 65/150\n",
      "68262/68262 [==============================] - 1s 19us/step - loss: 0.0224 - accuracy: 0.9926 - val_loss: 0.0847 - val_accuracy: 0.9786\n",
      "Epoch 66/150\n",
      "68262/68262 [==============================] - 1s 17us/step - loss: 0.0225 - accuracy: 0.9924 - val_loss: 0.0873 - val_accuracy: 0.9753\n",
      "Epoch 67/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0224 - accuracy: 0.9924 - val_loss: 0.0885 - val_accuracy: 0.9757\n",
      "Epoch 68/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0228 - accuracy: 0.9923 - val_loss: 0.0864 - val_accuracy: 0.9785\n",
      "Epoch 69/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0224 - accuracy: 0.9925 - val_loss: 0.0865 - val_accuracy: 0.9801\n",
      "Epoch 70/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0226 - accuracy: 0.9925 - val_loss: 0.0875 - val_accuracy: 0.9736\n",
      "Epoch 71/150\n",
      "68262/68262 [==============================] - 1s 19us/step - loss: 0.0225 - accuracy: 0.9925 - val_loss: 0.0933 - val_accuracy: 0.9706\n",
      "Epoch 72/150\n",
      "68262/68262 [==============================] - 1s 19us/step - loss: 0.0226 - accuracy: 0.9926 - val_loss: 0.0874 - val_accuracy: 0.9714\n",
      "Epoch 73/150\n",
      "68262/68262 [==============================] - 1s 16us/step - loss: 0.0223 - accuracy: 0.9926 - val_loss: 0.0821 - val_accuracy: 0.9744\n",
      "Epoch 74/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0228 - accuracy: 0.9925 - val_loss: 0.0855 - val_accuracy: 0.9833\n",
      "Epoch 75/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0224 - accuracy: 0.9926 - val_loss: 0.0841 - val_accuracy: 0.9747\n",
      "Epoch 76/150\n",
      "68262/68262 [==============================] - 1s 20us/step - loss: 0.0224 - accuracy: 0.9924 - val_loss: 0.0842 - val_accuracy: 0.9826\n",
      "Epoch 77/150\n",
      "68262/68262 [==============================] - 1s 19us/step - loss: 0.0224 - accuracy: 0.9928 - val_loss: 0.0900 - val_accuracy: 0.9734\n",
      "Epoch 78/150\n",
      "68262/68262 [==============================] - 1s 20us/step - loss: 0.0225 - accuracy: 0.9923 - val_loss: 0.0813 - val_accuracy: 0.9847\n",
      "Epoch 79/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0220 - accuracy: 0.9927 - val_loss: 0.0842 - val_accuracy: 0.9808\n",
      "Epoch 80/150\n",
      "68262/68262 [==============================] - 1s 17us/step - loss: 0.0224 - accuracy: 0.9929 - val_loss: 0.0901 - val_accuracy: 0.9804\n",
      "Epoch 81/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0223 - accuracy: 0.9923 - val_loss: 0.0880 - val_accuracy: 0.9738\n",
      "Epoch 82/150\n",
      "68262/68262 [==============================] - 1s 19us/step - loss: 0.0227 - accuracy: 0.9923 - val_loss: 0.0866 - val_accuracy: 0.9781\n",
      "Epoch 83/150\n",
      "68262/68262 [==============================] - 1s 20us/step - loss: 0.0219 - accuracy: 0.9925 - val_loss: 0.0880 - val_accuracy: 0.9797\n",
      "Epoch 84/150\n",
      "68262/68262 [==============================] - 2s 26us/step - loss: 0.0223 - accuracy: 0.9925 - val_loss: 0.0923 - val_accuracy: 0.9726\n",
      "Epoch 85/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0221 - accuracy: 0.9923 - val_loss: 0.0892 - val_accuracy: 0.9718\n",
      "Epoch 86/150\n",
      "68262/68262 [==============================] - 1s 19us/step - loss: 0.0222 - accuracy: 0.9924 - val_loss: 0.0917 - val_accuracy: 0.9757\n",
      "Epoch 87/150\n",
      "68262/68262 [==============================] - 1s 21us/step - loss: 0.0223 - accuracy: 0.9926 - val_loss: 0.0873 - val_accuracy: 0.9731\n",
      "Epoch 88/150\n",
      "68262/68262 [==============================] - 2s 28us/step - loss: 0.0220 - accuracy: 0.9926 - val_loss: 0.0915 - val_accuracy: 0.9727\n",
      "Epoch 89/150\n",
      "68262/68262 [==============================] - 2s 27us/step - loss: 0.0222 - accuracy: 0.9926 - val_loss: 0.0904 - val_accuracy: 0.9719\n",
      "Epoch 90/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0219 - accuracy: 0.9927 - val_loss: 0.0871 - val_accuracy: 0.9780\n",
      "Epoch 91/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0221 - accuracy: 0.9925 - val_loss: 0.0899 - val_accuracy: 0.9746\n",
      "Epoch 92/150\n",
      "68262/68262 [==============================] - 2s 29us/step - loss: 0.0222 - accuracy: 0.9925 - val_loss: 0.0880 - val_accuracy: 0.9731\n",
      "Epoch 93/150\n",
      "68262/68262 [==============================] - 2s 29us/step - loss: 0.0217 - accuracy: 0.9928 - val_loss: 0.0891 - val_accuracy: 0.9724\n",
      "Epoch 94/150\n",
      "68262/68262 [==============================] - 1s 20us/step - loss: 0.0222 - accuracy: 0.9925 - val_loss: 0.0859 - val_accuracy: 0.9731\n",
      "Epoch 95/150\n",
      "68262/68262 [==============================] - 1s 17us/step - loss: 0.0217 - accuracy: 0.9925 - val_loss: 0.0884 - val_accuracy: 0.9734\n",
      "Epoch 96/150\n",
      "68262/68262 [==============================] - 1s 19us/step - loss: 0.0219 - accuracy: 0.9928 - val_loss: 0.0888 - val_accuracy: 0.9734\n",
      "Epoch 97/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0218 - accuracy: 0.9928 - val_loss: 0.0900 - val_accuracy: 0.9715\n",
      "Epoch 98/150\n",
      "68262/68262 [==============================] - 1s 20us/step - loss: 0.0220 - accuracy: 0.9928 - val_loss: 0.0804 - val_accuracy: 0.9823\n",
      "Epoch 99/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0218 - accuracy: 0.9928 - val_loss: 0.0887 - val_accuracy: 0.9748\n",
      "Epoch 100/150\n",
      "68262/68262 [==============================] - 1s 21us/step - loss: 0.0217 - accuracy: 0.9927 - val_loss: 0.0883 - val_accuracy: 0.9731\n",
      "Epoch 101/150\n",
      "68262/68262 [==============================] - 1s 17us/step - loss: 0.0218 - accuracy: 0.9927 - val_loss: 0.0847 - val_accuracy: 0.9789\n",
      "Epoch 102/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0217 - accuracy: 0.9927 - val_loss: 0.0879 - val_accuracy: 0.9709\n",
      "Epoch 103/150\n",
      "68262/68262 [==============================] - 1s 17us/step - loss: 0.0218 - accuracy: 0.9925 - val_loss: 0.0819 - val_accuracy: 0.9859\n",
      "Epoch 104/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0217 - accuracy: 0.9928 - val_loss: 0.0852 - val_accuracy: 0.9786\n",
      "Epoch 105/150\n",
      "68262/68262 [==============================] - 1s 19us/step - loss: 0.0221 - accuracy: 0.9925 - val_loss: 0.0880 - val_accuracy: 0.9748\n",
      "Epoch 106/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0218 - accuracy: 0.9927 - val_loss: 0.0792 - val_accuracy: 0.9844\n",
      "Epoch 107/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0216 - accuracy: 0.9927 - val_loss: 0.0938 - val_accuracy: 0.9672\n",
      "Epoch 108/150\n",
      "68262/68262 [==============================] - 2s 23us/step - loss: 0.0223 - accuracy: 0.9927 - val_loss: 0.0821 - val_accuracy: 0.9848\n",
      "Epoch 109/150\n",
      "68262/68262 [==============================] - 1s 20us/step - loss: 0.0216 - accuracy: 0.9929 - val_loss: 0.0846 - val_accuracy: 0.9804\n",
      "Epoch 110/150\n",
      "68262/68262 [==============================] - 1s 19us/step - loss: 0.0218 - accuracy: 0.9925 - val_loss: 0.0900 - val_accuracy: 0.9718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0218 - accuracy: 0.9925 - val_loss: 0.0889 - val_accuracy: 0.9837\n",
      "Epoch 112/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0216 - accuracy: 0.9927 - val_loss: 0.0913 - val_accuracy: 0.9715\n",
      "Epoch 113/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0216 - accuracy: 0.9930 - val_loss: 0.0903 - val_accuracy: 0.9732\n",
      "Epoch 114/150\n",
      "68262/68262 [==============================] - 1s 17us/step - loss: 0.0220 - accuracy: 0.9927 - val_loss: 0.0867 - val_accuracy: 0.9727\n",
      "Epoch 115/150\n",
      "68262/68262 [==============================] - 1s 20us/step - loss: 0.0217 - accuracy: 0.9928 - val_loss: 0.0895 - val_accuracy: 0.9730\n",
      "Epoch 116/150\n",
      "68262/68262 [==============================] - 1s 21us/step - loss: 0.0217 - accuracy: 0.9924 - val_loss: 0.0934 - val_accuracy: 0.9742\n",
      "Epoch 117/150\n",
      "68262/68262 [==============================] - 1s 21us/step - loss: 0.0216 - accuracy: 0.9928 - val_loss: 0.0899 - val_accuracy: 0.9727\n",
      "Epoch 118/150\n",
      "68262/68262 [==============================] - 1s 19us/step - loss: 0.0219 - accuracy: 0.9926 - val_loss: 0.0808 - val_accuracy: 0.9822\n",
      "Epoch 119/150\n",
      "68262/68262 [==============================] - 2s 23us/step - loss: 0.0217 - accuracy: 0.9927 - val_loss: 0.0899 - val_accuracy: 0.9721\n",
      "Epoch 120/150\n",
      "68262/68262 [==============================] - 1s 21us/step - loss: 0.0215 - accuracy: 0.9928 - val_loss: 0.0870 - val_accuracy: 0.9805\n",
      "Epoch 121/150\n",
      "68262/68262 [==============================] - 1s 20us/step - loss: 0.0219 - accuracy: 0.9927 - val_loss: 0.0918 - val_accuracy: 0.9715\n",
      "Epoch 122/150\n",
      "68262/68262 [==============================] - 1s 20us/step - loss: 0.0213 - accuracy: 0.9930 - val_loss: 0.0857 - val_accuracy: 0.9830\n",
      "Epoch 123/150\n",
      "68262/68262 [==============================] - 1s 22us/step - loss: 0.0217 - accuracy: 0.9928 - val_loss: 0.0941 - val_accuracy: 0.9727\n",
      "Epoch 124/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0216 - accuracy: 0.9928 - val_loss: 0.0865 - val_accuracy: 0.9784\n",
      "Epoch 125/150\n",
      "68262/68262 [==============================] - 1s 20us/step - loss: 0.0219 - accuracy: 0.9924 - val_loss: 0.0887 - val_accuracy: 0.9752\n",
      "Epoch 126/150\n",
      "68262/68262 [==============================] - 1s 21us/step - loss: 0.0218 - accuracy: 0.9928 - val_loss: 0.0843 - val_accuracy: 0.9850\n",
      "Epoch 127/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0213 - accuracy: 0.9929 - val_loss: 0.0888 - val_accuracy: 0.9730\n",
      "Epoch 128/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0213 - accuracy: 0.9931 - val_loss: 0.0872 - val_accuracy: 0.9744\n",
      "Epoch 129/150\n",
      "68262/68262 [==============================] - 1s 21us/step - loss: 0.0215 - accuracy: 0.9925 - val_loss: 0.0964 - val_accuracy: 0.9718\n",
      "Epoch 130/150\n",
      "68262/68262 [==============================] - 1s 21us/step - loss: 0.0216 - accuracy: 0.9928 - val_loss: 0.0919 - val_accuracy: 0.9730\n",
      "Epoch 131/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0214 - accuracy: 0.9929 - val_loss: 0.0832 - val_accuracy: 0.9743\n",
      "Epoch 132/150\n",
      "68262/68262 [==============================] - 1s 20us/step - loss: 0.0216 - accuracy: 0.9929 - val_loss: 0.0816 - val_accuracy: 0.9844\n",
      "Epoch 133/150\n",
      "68262/68262 [==============================] - 1s 22us/step - loss: 0.0215 - accuracy: 0.9927 - val_loss: 0.0851 - val_accuracy: 0.9826\n",
      "Epoch 134/150\n",
      "68262/68262 [==============================] - 1s 21us/step - loss: 0.0221 - accuracy: 0.9923 - val_loss: 0.0846 - val_accuracy: 0.9839\n",
      "Epoch 135/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0212 - accuracy: 0.9929 - val_loss: 0.0892 - val_accuracy: 0.9732\n",
      "Epoch 136/150\n",
      "68262/68262 [==============================] - 1s 19us/step - loss: 0.0216 - accuracy: 0.9928 - val_loss: 0.0875 - val_accuracy: 0.9747\n",
      "Epoch 137/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0213 - accuracy: 0.9925 - val_loss: 0.0848 - val_accuracy: 0.9829\n",
      "Epoch 138/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0214 - accuracy: 0.9929 - val_loss: 0.0891 - val_accuracy: 0.9759\n",
      "Epoch 139/150\n",
      "68262/68262 [==============================] - 1s 19us/step - loss: 0.0214 - accuracy: 0.9928 - val_loss: 0.0874 - val_accuracy: 0.9746\n",
      "Epoch 140/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0212 - accuracy: 0.9929 - val_loss: 0.0787 - val_accuracy: 0.9852\n",
      "Epoch 141/150\n",
      "68262/68262 [==============================] - 1s 17us/step - loss: 0.0217 - accuracy: 0.9927 - val_loss: 0.0842 - val_accuracy: 0.9794\n",
      "Epoch 142/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0213 - accuracy: 0.9929 - val_loss: 0.0880 - val_accuracy: 0.9848\n",
      "Epoch 143/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0214 - accuracy: 0.9929 - val_loss: 0.0825 - val_accuracy: 0.9850\n",
      "Epoch 144/150\n",
      "68262/68262 [==============================] - 1s 20us/step - loss: 0.0213 - accuracy: 0.9929 - val_loss: 0.0922 - val_accuracy: 0.9746\n",
      "Epoch 145/150\n",
      "68262/68262 [==============================] - 1s 17us/step - loss: 0.0216 - accuracy: 0.9927 - val_loss: 0.0863 - val_accuracy: 0.9769\n",
      "Epoch 146/150\n",
      "68262/68262 [==============================] - 1s 19us/step - loss: 0.0214 - accuracy: 0.9929 - val_loss: 0.0925 - val_accuracy: 0.9743\n",
      "Epoch 147/150\n",
      "68262/68262 [==============================] - 1s 19us/step - loss: 0.0213 - accuracy: 0.9929 - val_loss: 0.0872 - val_accuracy: 0.9743\n",
      "Epoch 148/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0210 - accuracy: 0.9930 - val_loss: 0.0866 - val_accuracy: 0.9804\n",
      "Epoch 149/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0215 - accuracy: 0.9926 - val_loss: 0.0826 - val_accuracy: 0.9848\n",
      "Epoch 150/150\n",
      "68262/68262 [==============================] - 1s 18us/step - loss: 0.0208 - accuracy: 0.9932 - val_loss: 0.0887 - val_accuracy: 0.9755\n"
     ]
    }
   ],
   "source": [
    "history_class = classifier.fit(x=input_data, y=labels, epochs=150, validation_split=0.10, batch_size=75,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history_class.history['accuracy'])\n",
    "#plt.plot(history_class.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save('./models/my_models/classifier_model03.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
